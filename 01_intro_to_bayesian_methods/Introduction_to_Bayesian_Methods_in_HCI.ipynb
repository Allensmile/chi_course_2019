{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"imgs/chi2019_logo_final.png\">\n",
    "\n",
    "# Bayesian Methods in HCI\n",
    "\n",
    "\n",
    "$$\\newcommand{\\vec}[1]{{\\bf #1} } \n",
    "\\newcommand{\\real}{\\mathbb{R} }\n",
    "\\newcommand{\\expect}[1]{\\mathbb{E}[#1] }\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "$$\n",
    "\n",
    "----\n",
    "\n",
    "## John H. Williamson \n",
    "\n",
    "* **University of Glasgow**\n",
    "* JohnH.Williamson@glasgow.ac.uk / [johnhw.com](johnhw.com)\n",
    "* @jhnhw  \n",
    "* [github.com/johnhw](https://github.com/johnhw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Computational Interaction?\n",
    "**Computational interaction** applies computational thinking (abstraction, automation, analysis) to explain and enhance interaction between a user and a system. It is underpinned by modelling which admits formal reasoning, and which is amenable to computational approaches.\n",
    "\n",
    "There's even a book:\n",
    "\n",
    "<img src=\"imgs/comp_interaction_book.jpg\">\n",
    "\n",
    "*[Edited by Antti Oulasvirta, Per Ola Kristensson, Xiaojun Bi, and Andrew Howes]*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Computational interaction draws on insight from:\n",
    "* machine learning;\n",
    "* signal processing;\n",
    "* information theory;\n",
    "* optimisation;\n",
    "* Bayesian inference;\n",
    "* control theory;\n",
    "* and formal modelling.\n",
    "\n",
    "It emphasises generating motor themes in HCI, and robust, replicable and durable approaches which go beyond point sampling of the interaction space.\n",
    "\n",
    "### Computational interaction would typically involve at least one of:\n",
    "* I. an explicit **mathematical model** of user-system behaviour;\n",
    "* II. a way of **updating** that model with observed data from users;\n",
    "* III. an algorithmic element that, using this model, can **directly synthesise or adapt** the\n",
    "design;\n",
    "* IV. a way of **automating and instrumenting** the modelling and design process;\n",
    "* V. the ability to **simulate or synthesise** elements of the expected user-system behaviour.\n",
    "\n",
    "Computational interaction often involves elements from machine learning, signal processing, information theory,\n",
    "optimisation, inference, control theory and formal modelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian methods in HCI\n",
    "\n",
    "\n",
    "A **Bayesian**:\n",
    "\n",
    "* Represents belief over possibilities using probability distributions.\n",
    "* Updates belief using Bayes' Rule, combining a prior belief with observed evidence.\n",
    "* Infers conditional distributions over unseen parameters.\n",
    "\n",
    "Given a parameterised simulator that approximates the problem we are interested in, and some idea about what values these parameters could take on (expressed as a prior probability distribution) we can then use evidence to concentrate belief on more likely parameter configurations.\n",
    "\n",
    "---\n",
    "\n",
    "## The mysterious entity cartoon\n",
    "\n",
    "<img src=\"imgs/entity.png\">\n",
    "\n",
    "We observe data from a mysterious entity, like a user seen through the lens of a sensor. \n",
    "\n",
    "We have a \"tame\" mysterious entity governed by knobs (parameters) we can adjust; an approximation to a user and their local environment, perhaps. \n",
    "\n",
    "This has an input: the **likelihood** of observations under current parameter settings, and an output: the ability to **sample** new synthetic observations under the current parameters. We have a belief distribution over knob settings, and can update this based upon observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Bayesian methods have application throughout virtually of all of HCI, but are often only encountered in a few specialised niches; for example in speech recognition. There are a wide variety of areas where Bayesian methods can be directly *used* in HCI, three of the most well-explored being:\n",
    "\n",
    "* **Bayesian methods in empirical analysis** (i.e. Bayesian statistics for analysing experimental work): Bayesian analysis offers a potentially superior way of analysing some kinds of quantitative experimental work that arise in HCI. It can directly answer questions of interest and can incorporate first-principles models from domain experts. There are opportunities for novel experimental designs (e.g. online Bayesian experimental design) and meta-analyses. The advance of easy-to-use packages for Bayesian inference (e.g. Stan, brms) makes relatively sophisticated inference models practical for researchers. (**\"Statistical Rethinking\" by Richard McElreath** is recommended reading as a non-HCI specific elementary introduction to Bayesian data analysis)\n",
    "\n",
    "<img src=\"imgs/ymxc_stochastic.png\" width=\"60%\">\n",
    "<img src=\"imgs/sampled_posterior_predictive.png\">\n",
    "\n",
    "* **Bayesian methods in optimisation**: Bayesian optimisation can be used to optimise functions which are not easy to evaluate, or are noisy to evaluate. This is typically the case in optimisation with observations from users, who are expensive to measure, noisy and not governed by simple mathematical formulae. This can range from simple Bayesian A/B testing to sophisticated modelling of user behaviour at a fine level of granularity. Bayesian optimisation can be applied to a huge range of problems with expensive or noisy functions, from inferring subjective preferences to optimising touch sensor configurations. Proxy models like Gaussian Processes are well-supported by software tools.\n",
    "\n",
    "<img src=\"imgs/bayesian_optimization.jpeg\"> \n",
    "\n",
    "*[From the emukit documentation: https://amzn.github.io/emukit/bayesian-optimization/]*\n",
    "\n",
    "* **Bayesian methods in input decoding**: Bayesian methods can be used to represent the problem of the interface itself -- how does information flow from human to computer? This can be used to derive robust models based around inference of intention. Strong prior models of what we expect users to do allow us to extract maximum value from user actions and preserve and use uncertainty about user intent. This is a philosophy of interaction founded in the idea of the interface as a concentrator of belief, whose mechanics are driven by the logic of probability.\n",
    "\n",
    "<img src=\"imgs/capture.png\" width=\"50%\">\n",
    "\n",
    "*[Bayesian inference of gesture recognition]*\n",
    "\n",
    "* **Bayesian models of user population behaviour** Probabilistic predictive models can be used to capture how populations of users behave, and reason about likely future behaviours. Generative models of behaviour can be conditioned on observations, and even relatively small amounts of real-world data can be used to get powerful insights when strong first-principles models are brought to bear.\n",
    "\n",
    "\n",
    "There are other topics where Bayesian ideas have bearing on problems in interaction design, including:\n",
    "* **Interaction with Bayesian models**, that is how to explain, explore, understand and make help users make decisions with probabilistic models (see e.g. [Explorable Multiverse Analyses](https://explorablemultiverse.github.io/)). This is a problem of communicating distributions and computations upon them.\n",
    "\n",
    "* **Bayesian models of human cognition and activity** which seek to explain human (user) behaviour, from low-level motor actions and perceptual functions through to decision making, as approximate Bayesian inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian filtering for intention inference\n",
    "\n",
    "#### Inferring user intention in a noisy world\n",
    "----\n",
    "\n",
    "    All theorems are true. \n",
    "    All models are wrong. \n",
    "    And all data are inaccurate. \n",
    "\n",
    "    What are we to do? \n",
    "    We must be sure to remain uncertain.\n",
    "\n",
    "-- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This section will cover probabilistic **inference**. Rather than learning a single set of parameters by optimisation, we can infer probability distributions over possible configurations of models that might be compatible with our data. Our \"models\" will be representations of user intentions and parameters of the processes that transduce intention into sensor measurement.\n",
    "\n",
    "We will develop the idea of **probabilistic filtering** to rigorously define the interaction problem as online probabilistic inference over time, and derive practical algorithms that can be fuse together input device signals across time and across sensors channels. This will give us a robust, theoretically underpinned way of combining together sensing into estimates of intention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this relevant for computational HCI?\n",
    "* We will build **statistical models** of user behaviour, and estimate parameters of that model from quantitative observations of data. \n",
    "* This is a **model-led approach** which has a strong mathematical underpinning and many powerful algorithmic tools which can be brought to bear.\n",
    "* This is **robust** (it appropriately represents uncertainty) and **generative** (it can simulate behaviour compatible with observations).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "# Principles \n",
    "-------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> Interaction is the process of driving a system into a state compatible with user intentions.\n",
    "\n",
    "<img src=\"imgs/brainspace.png\" width=\"100%\">\n",
    "\n",
    "Note that we focus here on the problem of **input**; getting a computer to do what we want. We will touch on the problem of **feedback** where we aligning users with the processes mediating this input using some form of display. However, we will not consider the **display** problem, where we try to efficiently inject information from a computer into a user's mind.\n",
    "\n",
    "## Perspectives\n",
    "There are many perspectives on interaction that arise from this stance, including:\n",
    "\n",
    "| Perspective   | Burden | Characteristic                         |\n",
    "|---------------|--------|----------------------------------------|\n",
    "| Communication | User   | User gets information into the system, by encoding intentions. |\n",
    "| Control       | Split  | User drives state towards intention via feedback control.   |\n",
    "| Inference     | System | System infers what user intention is from sensed user actions. |\n",
    "\n",
    "## Interaction as inference\n",
    "If we view interaction as inference of intention, there are three elements:\n",
    "* **Interaction is inference**; it is the process of inferring a distribution over a hidden variable: what the user wants a system to do. \n",
    "* **Observations are indirect, noisy and incomplete** What a system sees is a distorted and incomplete representation of user actions in the world, which are in turn a noisy representation of internal intentions (your hand does not always go where you want it...)\n",
    "* **Interaction occurs over time** Interaction is a *process* that evolves over time. Information flow is not instantaneous. Observations must be fused together to update a beliefs.\n",
    "\n",
    "### Optimal mindreading\n",
    "We'll look at a **Bayesian** approach to modelling human computer interaction, where we explicitly model what might be going on inside a user's mind and use Bayesian methods to try and perform \"optimal mindreading\". \n",
    "\n",
    "<img src=\"imgs/brain_inference.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concentrating belief\n",
    "This view on interaction sees user intentions as **unknown values** which are partially observed through inputs. The time series of inputs from the user give a partial, noisy, incomplete view of intention inside the user's head, along with a great deal of superfluous information. \n",
    "\n",
    "We try and infer intention *generative model* which is a simplified representation of intention and how it is mediated and transformed by the world. The stronger model we have available, the more effectively we can infer intention.\n",
    "\n",
    "> In this view, improving interaction (or at least *input*) comes down to more efficiently concentrating probability density where a user wants it. A better pointing device reduces uncertainty faster; a better display helps a user understand how best to target future actions to concentrate belief as desired; a better model of the user intentions concentrates belief with less explicit effort on the part of a user.\n",
    "\n",
    "<img src=\"imgs/contraction_probability.png\" width=\"70%\">\n",
    "\n",
    "## Partitioning the inferred variables\n",
    "\n",
    "We can further partition the problem. The causes of observed evidence can be factored, for example, into:\n",
    "\n",
    "* **Mind state** The parameters of the intentions that generate the behaviour: what menu option does the user want?\n",
    "* **World state** The parameters of the motor system that generate movement: where is the user's hand?\n",
    "* **Sensor state** The parameters of the sensing system that generates signals: what is the camera matrix?\n",
    "\n",
    "$$P(X_{\\text{intention}}, X_{\\text{motor}}, X_{\\text{sensing}}|Y)$$\n",
    "\n",
    "[Betancourt's article on probabilistic modeling](https://betanalpha.github.io/assets/case_studies/modeling_and_inference.html) expresses these ideas in terms of the \"phenomenon\" (intention), \"environment\" (motor/world system) and \"probe\" (sensing/interface context)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "# Probability refresher\n",
    "\n",
    "## Random variables and distributions\n",
    "A **random variable** $X$ is a variable that can take on different values, but we do not know what value it has; i.e. one that is \"unassigned\". However, we have knowledge which captures the possible states the variable could take on, and their corresponding probabilities, which is encoded in the **distribution** of that variable. Probability theory allows us to manipulate random variables without having to assign them a specific value.\n",
    "\n",
    "A random variable might represent:\n",
    "\n",
    "* the outcome of dice throw (discrete), i.e. over the set of outcomes $\\{1,2,3,4,5,6\\}$; \n",
    "* whether or not it is raining outside (discrete: binary), over the set of outcomes $\\{\\text{heads}, \\text{tails}\\}$; \n",
    "* the height of person we haven't met yet (continuous), over the set of outcomes $\\real$; \n",
    "* the position of a user's hand (continuous, multi-dimensional), over the set of outcomes $\\real^3$. \n",
    "\n",
    "## Distributions\n",
    "A **probability distribution** defines how likely different states of a random variable are. \n",
    "\n",
    "We can see $X$ as the the *experiment* and $x$ as the *outcome*, with a function mapping every possible outcome to a probability. \n",
    "\n",
    "$$P(X=x),\\  \\text{the probability of random variable X taking on value x}\\\\\n",
    "P(X),\\  \\text{shorthand for probability of X=x }\\\\\n",
    "$$\n",
    "\n",
    "### Discrete and continuous\n",
    "\n",
    "The function defining the distribution maps the outcomes of a random variables to real numbers (probabilities) in the range $[0,1]$, subject to the constraint that the sum of all probabilities across all outcomes. These probabilities, in a Bayesian world view, represent belief about how likely different outcomes are. Distributions are defined by functions $f_X(x)$, which give the probability of an outcome $x$ (imagine a dictionary mapping outcomes to probabilities). For technical reasons, these are distinghuised as **probability mass function** (PMF),  for discrete variables and  **probability density functions** (PDF), for continuous variables.\n",
    "\n",
    "### Likelihood and probability\n",
    "* We talk about the **probability** of outcomes we have not yet observed: how relatively likely are future possible states?\n",
    "* We talk about the **likelihood** of outcomes we have observed: how likely is the data we have observed to have been generated by the distribution we have? We sometimes write the likelihood of an observation $x$ as $\\mathcal{L}(x) = f_X(x)$ and is just evaluated by evaluating the mass/density function at $x$.\n",
    "\n",
    "## Samples, outcomes and sampling\n",
    "**Samples** are observed outcomes of an experiment; we will use the term **observations** to refer to the same thing when samples come from measurements, rather than being simulated. We can **sample** from a distribution; this means simulating outcomes according to the probability distribution of those variables. We can talk about the probability of generating a specific sample; and the likelihood of a given observation having being generated.\n",
    "\n",
    "For discrete random variables, this is easy: we simply produce samples by drawing each outcome according to its probability. (For continuous variables, we need to use specific algorithms to draw samples according to a distribution.)\n",
    "\n",
    "---\n",
    "\n",
    "## Random variables\n",
    "\n",
    "* Defined over a set of outcomes (e.g. `{heads, tails}` or the real numbers, or the set of `[longitude, latitude, altitude]` tuples, etc.)\n",
    "* Defined by a function: probability mass/density function, which maps each outcome to a \"belief weight\" (probability) such that the integral/sum of all weights is 1.0\n",
    "* Key operations:\n",
    "    * **Likelihood**, which just evaluates the density/mass function at some value, i.e. evaluating $f_X(x)$ or $P(X=x)$ at some known $x$. We typically want to be able to compute the *log-likelihood*, as a more computationally useful form.    \n",
    "    * **Sample**, simulating an example from a random variable, i.e. drawing a new random $x$ such that the long-term distribution of many such samples follows the distribution that defines the random variable.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "# numpy, scipy\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "# add our custom scripts\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "# custom packages from src/\n",
    "import pfilter, gestures\n",
    "\n",
    "# matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(8.0, 4.0), dpi=80)\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A definition of a probabilty distribution in Python\n",
    "# This is all we really need for *any* inference (though many convenience methods\n",
    "# typically also defined)\n",
    "\n",
    "class RandomVariable:\n",
    "    def __init__(self, pmf):\n",
    "        self.pmf = pmf\n",
    "\n",
    "    def lik(self, outcome):\n",
    "        \"\"\"Return the likelihood of some outcome; i.e. evaluate\"\"\"\n",
    "        return self.pmf[outcome]\n",
    "\n",
    "    def sample(self, n):\n",
    "        \"\"\"Draw a random sample from this random variable; i.e. simulate\"\"\"\n",
    "        return np.random.choice(list(self.pmf.keys()),\n",
    "                                n,\n",
    "                                p=list(self.pmf.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin = RandomVariable({\"heads\":0.5, \"tails\":0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Likelihood of observing heads\", coin.lik(\"heads\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"10 random draws from an unbiased coin:\\n\" + \"\\n\".join(coin.sample(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = RandomVariable({\n",
    "    1: 1 / 24,\n",
    "    2: 4 / 24,\n",
    "    3: 10 / 24,\n",
    "    4: 4 / 24,\n",
    "    5: 4 / 24,\n",
    "    6: 1 / 24\n",
    "})\n",
    "\n",
    "print(\"10 random draws from an biased die:\\n\", dice.sample(10))\n",
    "print(\"Likelihood of 3\", dice.lik(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we can we do with this?\n",
    "\n",
    "* We can **simulate** by *sampling* from a distribution.\n",
    "* We can **evaluate** by computing *likelihoods* of observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bayesian\"> </a>\n",
    "## Probability theory and Bayesian inference\n",
    "\n",
    "#### Probability as a calculus of belief\n",
    "*Bayesians* treat probability as a **calculus of belief**; in this model of thought, probabilities are measures of degrees of belief. $P(X=x)=0$ means a belief that outcome $x$ can never occur and $P(X=x)=1$ is a belief that outcome $x$ is absolutely certain.belief in its viability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The key process in Bayesian logic is *updating of beliefs*. Bayesian inference requires that we accept *priors* over events. \n",
    "\n",
    "* Given some **prior** belief (it's Glasgow, it's not likely to be sunny) \n",
    "* and some new **observations** for which we have a likelihood (there seems to be a bright reflection inside, and it is likely to be bright inside if it is sunny)\n",
    "* we can update our belief to calculate the **posterior** -- our new probability that it is sunny outside. \n",
    "\n",
    "This implies we must explicitly quantify our assumptions with probability distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior, likelihood, posterior, evidence\n",
    "\n",
    "\n",
    "We often have some **hypothesis** $H$ we want to know, given some **data** $D$ we observe, and we can write Bayes' Rule as:\n",
    "$$ \\begin{equation}P(H|D) = \\frac{P(D|H) P(H)}{P(D)} \\end{equation}$$\n",
    "\n",
    "(the probability of the hypothesis given the data) is equal to (the probability of the data given the hypothesis) times (the probability of the hypothesis) divided by (the probability of the data).\n",
    "\n",
    "\n",
    "In general $P(H|D) \\neq P(D|H);$\n",
    "\n",
    "* $P(H|D)$ is called the **posterior**\n",
    "* $P(D|H)$ is called the **likelihood**\n",
    "* $P(H)$ is the **prior**  \n",
    "* $P(D)$ is the **marginal likelihood** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian interaction for inference of intention\n",
    "\n",
    "If we look at the problem of **inferring intent**, then:\n",
    "\n",
    "* We have **evidence** from input devices (e.g. a sequence of mouse movements)\n",
    "* We have **prior distribution** over a space of intentions (e.g. how likely is it the user wants to select this item?)\n",
    "* We want to infer the **posterior** distribution over intentions, conditioned on the observed evidence.\n",
    "\n",
    "We can factor the posterior:\n",
    "\n",
    "* **intention** The \"simple\" explanation that exists in the user's head\n",
    "* **motor system** The expression of an intention through the motor system, influenced by the cognitive and physiological properties of the user\n",
    "* **sensing system** The way the expression of intention is mapped onto sensor states which capture the variations in the world.\n",
    "\n",
    "All of these components can have random parameters associated with them, and we can write down generative models that express these ideas in terms of these stages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' rule for combining evidence\n",
    "\n",
    "One particularly powerful part of this that in a sequential process, the posterior at one step becomes the prior at the next; we can accumulate evidence over time. **It makes no difference whether we accumulate all the evidence at once, or do so step by step; the resulting distribution will be identical.**\n",
    "\n",
    "\n",
    "<img src=\"imgs/recursive.png\" width=\"50%\">\n",
    "\n",
    "<a id=\"combining\"> </a>\n",
    "\n",
    "Bayes' rule is the (only) correct way to combine prior belief and observation to update beliefs. This can be used to \"learn\", where \"learning\" means updating a probability distribution based on observations. It has enormous applications anywhere uncertain information must be fused together, whether from multiple sources (e.g. sensor fusion) or over time (e.g. probabilistic filtering). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_demo import prior_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast convergence, strong belief in observed evidence, and informative prior\n",
    "prior_posterior(prior_mean=0, prior_std=0.75, ev_std=0.25, anim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weaker prior and less belief in evidence; slower convergence (but still works)\n",
    "prior_posterior(prior_mean=0, prior_std=3, ev_std=1.0, anim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# really bad prior, but this will eventually be forgotten   \n",
    "prior_posterior(prior_mean=-3, prior_std=1.0, ev_std=0.5, anim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Probabilistic filtering\n",
    "We'll specifically look at probabilistic filtering, which is just Bayesian updating over time. There are a collection of algorithms for doing so efficiently.  Probabilistic filtering **(PF)** tracks the evolution of some unknown variables *[user intentions]* given observed evidence *[user input]*, in a way that is **robust**. Probabilistic filters infer a **distribution** over possible hidden (unobserved) variables, updating them over time. These filters are:\n",
    "* inherently **uncertain**, as they represent degrees of belief as probability distributions over states\n",
    "* and **dynamic**, as they explicitly model changing state over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Properties\n",
    "Probabilistic filtering is:\n",
    "\n",
    "| Property | Why  |\n",
    "|----------|------|\n",
    "|**Bayesian**  |  Represents degrees of belief using probability distributions.    |\n",
    "|**predictive**  |  Works by comparing predictions with reality.   |\n",
    "|**generative** |  Involves generating (i.e. simulating) behaviour.   |\n",
    "\n",
    "-----\n",
    "Probabilistic filtering is an **inverse probability** approach, and it requires that we think of interaction from an unique perspective. We have to explicitly be able to write down:\n",
    "\n",
    "* what we want to know (i.e. the **state space of intentions and world states**), which describes hidden states that might give rise to observed behaviour;\n",
    "* how that will change over time (i.e. the **dynamics** of our model);\n",
    "*  a model that *if we knew what the user intention was, what the expected behaviour would be* (i.e. a **generative function mapping intention -> expected observations**).\n",
    "\n",
    "Note that this is the **inverse** of the typical way of approaching this problem, where we would try and find a mapping from a sensors to intention, by design or by learning. Instead, we propose that we can postulate intentions, and look for evidence that might favour some underlying intentions over others. This can be a subtle and powerful way of distinguishing intentions which are poorly represented in observed signals.\n",
    "\n",
    "### Simulation viewpoint\n",
    "These filters are really *simulators*. They *simulate* how possible user behaviours might unfold over time. In some probabilistic filters, hundreds of parallel simulators are run, each with slightly different parameters. In all cases, the simulations are adjusted online to better match observed reality. The internal parameters that drive the simulation are the *unknown variables* we want to infer and the *evidence* is the observed reality that adjusts the simulation parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this computational HCI?\n",
    "Probabilistic filtering means writing down an **executable, statistical model** of user behaviour, then **running an inference algorithm** that updates beliefs based on the way observations evolve. The **parameters** of the filter can be **learned from user data**. The effectiveness of the filter can be quantitatively measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What are competitive approaches?\n",
    "### **Crafted mappings**\n",
    "**where we try to find (by hand) transforms from sensors to intentions that are  simple or obvious.**\n",
    "\n",
    "**Example:** a button, which has two physical states, and maps on to two intentional states via two electrical states. Pushed down = current flows = user intended to switch on. The mapping from electrical states to intentional states is **designed.**\n",
    "\n",
    "This is is explicit design, which often puts the burden of mapping states <=> intentions on the user. Users have to learn to encode their intentions in physical actions which hopefully correspond \"intuitively\" with the crafted mappings that have been set up to detect them.\n",
    "\n",
    "<img src=\"imgs/undo.jpg\">\n",
    "\n",
    "*[Image credit: David Singleton via flickr.com CC-BY 2.0]*\n",
    "\n",
    "### **Machine learned mappings**\n",
    "**where we train a system to recognize a class of input patterns as being representative of an intended behaviour.**\n",
    "\n",
    "**Example:** Finger gesture recogniser; hundreds of examples of many users performing one of N multi-touch gestures are recorded. These are used to train a random forest to classify the intended gesture. The mapping from electrical states (capacitive sensors) to intentional states is **learned**.\n",
    "\n",
    "This reduces the burden on the user to learn a specific mapping and instead adapts to behaviours exhibited by real users with real input devices. But it can suffer with issues in generalisation and robustness, and is often very hard to combine with known first-principles models (e.g. users can't change the size of their fingers!)\n",
    "\n",
    "<img src=\"imgs/svm.jpg\" width=\"300px\">\n",
    "\n",
    "*[Image credit: Elisfm - via Wikimedia Commons; public domain]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Benefits of a probabilistic filtering approach\n",
    "\n",
    "Probabilistic filtering has a number of motivating properties that make it worth studying:\n",
    "\n",
    "### Stronger modelling\n",
    "* **Easy to incorporate priors** Prior knowledge is naturally and easily expressed. We write down a \"simulator\" that behaves  according to mechanics we can arbitrarily define and can build upon what we know about the world.\n",
    "* **Flexible modelling** PFs can incorporate both fundamental modelling (e.g. physiological or cognitive models) and data-driven machine learning.\n",
    "* **Easy to balance modelling with learning** We can fuse both learned components with prior models, either to efficiently emulate complex processes via learned surrogates, or to capture models for which we lack strong first-principles views.\n",
    "\n",
    "### Robust\n",
    "* **Robustness to noise** PFs can work well even with input sensors that are noisy.\n",
    "* **Robustness to poorly specified models** PFs can cope predictably even if our models are bad.\n",
    "* **Robustness to intermittence** PFs can continue to sensibly interpolate when input cuts out.\n",
    "\n",
    "### Decoupled\n",
    "\n",
    "* **Decoupled from real-time** PFs can infer past (smoothing), present (filtering) and future (forecasting).\n",
    "* **Inherent fusion of multiple input sensors** PFs are often used to solely to fuse together multiple inputs from different sensors.\n",
    "\n",
    "### Reflective\n",
    "* **Uncertainty estimates** PFs *know how certain they are* and this can be used in the interaction design.\n",
    "* **Better feedback** PFs  offer the opportunity to give users rich insight into the process of intention decoding.\n",
    "\n",
    "---\n",
    "\n",
    "## Drawbacks\n",
    "\n",
    "* Computational demands can be heavy, especially compared to black box prediction models.\n",
    "* Speeding up inference may require more sophisticated statistical models, and this can get tricky quickly.\n",
    "* If you **don't** have good models, then it may be easier to just learn from data, or force users to adapt to a design.\n",
    "* Distributions are not natural for users. Representing these so users understand what is going on can be tricky.\n",
    "* Rules have to be defined to turn inference into action, typically involving some form of utility function to make decisions. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic filtering\n",
    "We will use this recursive form of Bayesian updating to estimate user intentions online. \n",
    "\n",
    "This filter maintains a state distribution as a collection of discrete samples, which is used as prior for the next step of estimation. Evidence is observed, and a posterior is computed; this becomes the prior for the next step, after a **prediction** step is used to align the prior with the known or estimated behaviour.\n",
    "\n",
    "Unlike other filters, such filters maintain a **distribution** over some hidden variable we are trying to estimate. This makes it possible for them to cope with noise and uncertainty robustly. It also (slightly) complicates their implementation, but their are good models which are readily available.\n",
    "\n",
    "In HCI, at the very highest level, we want to estimate **state $X_t$** given **sensor observation $Y_t$** $P(X_t|Y_t)$, both of which change over time. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/landscape.png\" width=\"50%\">\n",
    "\n",
    "*[Waddington's epigenetic landscape, illustrating a dynamic system which develops multiple modes as it evolves]*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview diagram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/control_loop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terminology\"> </a>\n",
    "## Probabilistic filtering terminology \n",
    "\n",
    "Notation:\n",
    "* We have a sequence of states over time, indexed by $t$\n",
    "* $X_t$ the variable we want to know (at time $t$) (e.g. an intention inside a user's head). \n",
    "* $Y_t$ the variable we can observe (e.g. a sensor we can get readings from).\n",
    "* For computational simplicity, we assume **discrete time**, i.e. we observe sensors in a discrete, regularly sampled way.\n",
    "\n",
    "* We want to compute $P(X_t|Y_t)$ (the **inverse problem**). \n",
    "* We use a **forward model** $P(Y_t|X_t)$ to infer this.\n",
    "* We need to define two functions: ${\\bf\\hat{y_t}} = f({\\bf {x}}_t)$ (the **observation function**) and ${\\bf x}_{t} = g(\\hat{\\bf x}_{t-1})$ (the **dynamics** or **process function**).\n",
    "* We also need to compute the likelihood of the real observation given our model: $p(\\bf\\hat{y_t}|{\\bf y_t})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $f$, $g$ are often very simple functions.\n",
    "\n",
    "<img src=\"imgs/stochastic.png\" width=\"55%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**This is a predictor-corrector model**; the dynamics model supplies predictions, and corrections to those predictions are applied by the observation model.\n",
    "\n",
    "## Uses of probabilistic filters\n",
    "Probabilistic filters are applicable in many HCI tasks, wherever there is a process evolving over time and uncertainty about what users want to do. For example, we have used them extensively to track finger configurations when using capacitive sensors. In this case, we have a finger pose state space (hidden) and a sensor matrix (observed), and the filter estimates pose in real-time.\n",
    "\n",
    "<img src=\"imgs/finger_track.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm\n",
    "We will use the **particle filter** algorithm (technically the **SIR** variant, which is the simplest to understand).\n",
    "\n",
    "A particle filter requires that we specify:\n",
    "* A **dynamics function** $f(\\vec{x_t})$ that predicts (approximately) how we expect the world to evolve, which takes \n",
    "${\\bf{x}}_t \\rightarrow {\\bf x}_{t+1}$\n",
    "* An **observation function**  $g(\\vec{x_t})$  that predicts what we expect to observe, given a hypothesized state $\\vec{x_t} \\rightarrow \\hat{\\bf{y}_t}$\n",
    "* A **weight function**, $w(\\vec{y_t},  \\hat{\\vec{y_t}})$ that, given a hypothesized observation $\\hat{\\bf y}_t$, can be used to compute $p(\\hat{\\bf y}_t|{\\bf y}_t)$. This is performed by computing weights $w_i$ for each particle $i$ and then normalizing to produce a probability:\n",
    "$$p^{(i)}(\\hat{\\bf y}_t|{\\bf y}_t) = \\frac{w_i}{\\sum_j w_j}$$\n",
    "* A **prior distribution** that specify our initial guesses for $\\bf x_0$  which we can sample from.\n",
    "\n",
    "We apply these functions to a bank of samples (\"particles\"), which approximately represent a distribution. This is a computationally tractable way to perform filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example: the intermittent slider\n",
    "\n",
    "We have: \n",
    "\n",
    "* A simple 1D slider\n",
    "* We intermittently observe the position of the slider accurately\n",
    "* We continuously observe inaccurately the speed (not the velocity) of the slider\n",
    "* There are two boxes on the slider which represent actions to be performed.\n",
    "\n",
    "\n",
    "For example, we might have a computer vision system measuring a finger position which tracks badly, and a Doppler radar system which reports speed but for some reason cannot report the direction of that movement.\n",
    "\n",
    "\n",
    "`python intermittent_slider.py`\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "We want to infer -- is the user selecting box A or box B or neither?\n",
    "\n",
    "How can we model this? We could assume that the movement has some simple internal dynamics (i.e. the user moves the slider smoothly). This could be as simple as assuming that we have some current velocity of movement, which stays relatively constant.\n",
    "\n",
    "Our internal state is $$\\vec{x_t} = [x, \\dot{x}].$$\n",
    "\n",
    "Our observations are $$\\vec{y_t} = [x, |\\dot{x}|],$$ where $x$ may be missing in many measurements.\n",
    "\n",
    "We define some functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(n):\n",
    "    \"\"\"Return n initial draws from the prior over the position\n",
    "    and velocity of the cursor before any observations have been drawn\"\"\"\n",
    "    x_prior = np.random.uniform(0, 1, n)  # anywhere 0->1\n",
    "    dx_prior = np.random.normal(0, 0.5, n)  # slow movement\n",
    "    return np.stack([x_prior, dx_prior]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observation(particles):\n",
    "    \"\"\"Project from \n",
    "    internal state (x, dx) => observed states (x, speed)\"\"\"\n",
    "\n",
    "    x = particles[:, 0]\n",
    "    speed = np.abs(particles[:, 1])\n",
    "    # observations\n",
    "    return np.stack([x, speed]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamics(particles, dt):\n",
    "    \"\"\"Apply our very simple dynamics, with velocity and some\n",
    "    random noise, and return a new set of particles\"\"\"\n",
    "\n",
    "    new_particles = np.array(particles)  # copy\n",
    "    new_particles[:, 0] += particles[:, 1] * dt  # integrate\n",
    "    # diffuse\n",
    "    new_particles += np.random.normal(0, 1, particles.shape) * [2e-2, 1e-3]\n",
    "    return new_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "\n",
    "\n",
    "def weighting(hypothesised, real):\n",
    "    \"\"\"Compare a set of hypothesised observation values (one) real observation\n",
    "     and return a unnormalised weighting for each particle\"\"\"\n",
    "\n",
    "    # position, speed weights\n",
    "    # (note: these can be masked and therefore not contribute to the calculation)\n",
    "    weights = [5000.0, 50.0]\n",
    "\n",
    "    # squared difference, weighted and exponentiated\n",
    "    # this gives a similarity measure\n",
    "    difference = ma.sum((hypothesised - real)**2 * weights, axis=1)\n",
    "    return np.exp(-difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_step(particles, observed, dt=0.01, prior_rate=0.05):\n",
    "    \"\"\"Update one complete step given a set of particles\n",
    "    and an observation.\n",
    "    \n",
    "        Steps:\n",
    "        * Apply dynamics to the particles\n",
    "        * Compare with observations to get weights\n",
    "        * Normalise weights\n",
    "        * Resample particles according to weights\n",
    "        * Replace a small fraction of particles with \n",
    "            prior draws to \"refresh\" the sampler\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    new_particles = dynamics(particles, dt)  # dynamics\n",
    "\n",
    "    # replace a few particles with draws from the posterior\n",
    "    prior_draws = np.random.uniform(0, 1, len(particles)) < prior_rate\n",
    "    new_particles[prior_draws] = prior(np.sum(prior_draws))\n",
    "\n",
    "    weights = weighting(observation(new_particles), observed)  # weighting\n",
    "    normalised_weights = weights / np.sum(weights)  # normalise weights\n",
    "    new_particles = new_particles[pfilter.resample(\n",
    "        normalised_weights)]  # resampling\n",
    "\n",
    "    return new_particles, normalised_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_position(particles, normalised_weights):\n",
    "    \"\"\"Return the expectation of the particle position/speed (i.e. the average position)\"\"\"\n",
    "    return np.sum((particles.T * normalised_weights.T).T, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logged data\n",
    "\n",
    "We can run the slider and get some basic data about how the cursor moves around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_last_log(fname=None):\n",
    "    \"\"\"Load the last log file that was recorded, or the given filename\"\"\"\n",
    "    basepath = \"captured_data\"\n",
    "    if fname is None:\n",
    "        \n",
    "        files = os.listdir(basepath)\n",
    "        ordered_files = []\n",
    "        for file in files:\n",
    "            # find matching files and get time\n",
    "            if file.endswith(\".csv\") and file.startswith(\"slider\"):            \n",
    "                path = os.path.join(basepath, file)\n",
    "                mtime = os.path.getmtime(path)\n",
    "                ordered_files.append((mtime, path))\n",
    "\n",
    "        ordered_files = sorted(ordered_files)\n",
    "        last_csv =  ordered_files[-1][1]\n",
    "    else:\n",
    "        # just a plain filename\n",
    "        last_csv = os.path.join(basepath, fname)\n",
    "        \n",
    "    print(f\"Reading {last_csv}\")\n",
    "        \n",
    "    return pd.read_csv(last_csv)\n",
    "\n",
    "captured = load_last_log()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(value, title):\n",
    "    fig = plt.figure(); ax = fig.add_subplot(1,1,1)\n",
    "    kde = scipy.stats.gaussian_kde(value)\n",
    "    span = np.min(value), np.max(value)    \n",
    "    xs = np.linspace(span[0], span[1], 100)\n",
    "    ax.plot(xs, kde(xs))\n",
    "    ax.hist(value, bins=20, density=True)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot(captured.true_x, \"True cursor position\")\n",
    "hist_plot(captured.true_dx, \"True cursor velocity\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks\n",
    "\n",
    "One of the major advantages of a Bayesian generative model is that we can check if the properties we would expect to see hold in simulation. After all, we are writing down a simulator that can generate supposedly plausible behaviour.\n",
    "\n",
    "### Prior predictive checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = prior(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot(samples[:,0], 'Prior position')\n",
    "hist_plot(samples[:,1], 'Prior velocity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 20 random samples from the prior\n",
    "# should be randomly spread in the range [0,1], with some small initial velocity\n",
    "\n",
    "fig = plt.figure(figsize=(6, 2))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.quiver(samples[:, 0],\n",
    "          0 * samples[:, 0],\n",
    "          samples[:, 1],\n",
    "          0 * samples[:, 0],\n",
    "          units='x',\n",
    "          scale=10)\n",
    "ax.axvline(0.0, color='C1')\n",
    "ax.axvline(1.0, color='C1')\n",
    "ax.set_xlim(-0.2, 1.2)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_title(\"Prior draws\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draws from the random process\n",
    "We can sample the evolution of samples over time, to see whether the simple dynamics can capture the kinds of variation we might expect to see. Note that we will see much more variation in these processes than we would observe when conditioning on data; this is why the plots are so \"wiggly\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled evolutions, showing the dynamics without\n",
    "# any sampling process, unconditioned draws from\n",
    "# the random process\n",
    "samples = prior(20)\n",
    "\n",
    "# show 20 random trajectories\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "trajectories = []\n",
    "for i in range(120):\n",
    "    samples = dynamics(samples, 1 / 60.0)\n",
    "    trajectories.append(samples)\n",
    "\n",
    "trajectories = np.array(trajectories)\n",
    "\n",
    "for i in range(len(samples)):\n",
    "    ax.plot(trajectories[:, i, 0],\n",
    "            (1 / 60.0) * np.arange(0, len(trajectories[:, i, 0])))\n",
    "\n",
    "# Set the axis properties\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(\"Position\")\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "ax.set_title(\"Evolution over time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = prior(50)\n",
    "\n",
    "# show 20 random trajectories\n",
    "# but this time, we observe a speed of 0.5\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i in range(12):\n",
    "    # observe just the speed (we mask out the position using NaN)\n",
    "    observed = ma.masked_invalid([np.nan, 0.5])\n",
    "\n",
    "    # compute the new states and their weights\n",
    "    samples, weights = filter_step(samples,\n",
    "                                   observed=observed,\n",
    "                                   dt=1 / 6.0,\n",
    "                                   prior_rate=0.05)\n",
    "\n",
    "    ax.quiver(samples[:, 0], (1 / 6.0) * i + 0 * samples[:, 0],\n",
    "              samples[:, 1],\n",
    "              0 * samples[:, 0] + 0.5,\n",
    "              scale=20,\n",
    "              color='C0',\n",
    "              width=0.005)\n",
    "\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_xlabel(\"Position\")\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "ax.set_title(\"Evolution over time (fixed speed, free position)\")\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = prior(50)\n",
    "\n",
    "# show 50 random trajectories\n",
    "# but this time, we observe a static cursor at x=0.5\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "for i in range(12):\n",
    "    # observe just the speed\n",
    "    observed = ma.masked_invalid([0.5, 0.0])\n",
    "    samples, weights = filter_step(samples,\n",
    "                                   observed=observed,\n",
    "                                   dt=1 / 6.0,\n",
    "                                   prior_rate=0.05)\n",
    "\n",
    "    ax.scatter(x=samples[:, 0],\n",
    "               y=(1 / 6.0) * i + 0 * samples[:, 0],\n",
    "               c='C0',\n",
    "               s=weights * 100)\n",
    "\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_xlabel(\"Position\")\n",
    "ax.set_ylabel(\"Time (s)\")\n",
    "ax.set_title(\"Evolution over time (fixed position and speed)\")\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo\n",
    "\n",
    "`python intermittent_slider.py --block`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured = load_last_log()\n",
    "# captured = load_last_log(\"captured_data\\slider_Sun_May__5_11_35_09_2019.csv\")\n",
    "\n",
    "fig = plt.figure(figsize=(12,16))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "t = captured.t\n",
    "\n",
    "ax.plot(captured.true_x, t, label=\"True x\")\n",
    "ax.plot(captured.obs_x, t, 'C2d', label=\"Observed x\")\n",
    "ax.plot(captured.est_x, t, 'C3', label=\"Estimated x\")\n",
    "ax.fill_betweenx(t, captured.est_x-2*captured.std_x, captured.est_x+2*captured.std_x, alpha=0.2)\n",
    "ax.legend()\n",
    "ax.set_title(\"Position estimation\")\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "\n",
    "ax.set_title(\"Velocity estimation\")\n",
    "ax.plot(captured.true_dx, t, label=\"True dx\")\n",
    "ax.plot(captured.obs_speed, t, 'C2d', label=\"Observed speed\")\n",
    "ax.plot(captured.est_dx, t, 'C3', label=\"Estimated dx\")\n",
    "\n",
    "\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What have we done?\n",
    "\n",
    "This is a very simple model for a very simple problem. But it lets us deal with a lot of messiness in a principled manner. It has several attributes that would be difficult to approach in a coherent way with other techniques.\n",
    "\n",
    "* **Dealt with intermittency**: decoupled from real-time state, because our model has internal dynamics\n",
    "* **Represented uncertainty**: we know when control is good and when it is bad\n",
    "* **Decoded discrete outputs**: we have inferred continuous states, then mapped to a 1 of N choice\n",
    "* **Fused multiple sensors**: we combined the occasional, precise position measurement with continuous, ambiguous and noisy speed measurement\n",
    "* **Inferred hidden states**: we never observed or computed velocity, but we were able to update our distribution over possible values regardless."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
