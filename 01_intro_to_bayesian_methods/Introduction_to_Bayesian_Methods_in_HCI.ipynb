{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"imgs/chi2019_logo_final.png\">\n",
    "\n",
    "# Bayesian Methods in HCI\n",
    "\n",
    "\n",
    "$$\\newcommand{\\vec}[1]{{\\bf #1} } \n",
    "\\newcommand{\\real}{\\mathbb{R} }\n",
    "\\newcommand{\\expect}[1]{\\mathbb{E}[#1] }\n",
    "\\DeclareMathOperator*{\\argmin}{arg\\,min}\n",
    "$$\n",
    "\n",
    "## John H. Williamson \n",
    "\n",
    "* JohnH.Williamson@glasgow.ac.uk\n",
    "* [johnhw.com](johnhw.com)\n",
    "* jhnhw / Twitter\n",
    "* johnhw / GitHub\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Computational Interaction?\n",
    "**Computational interaction** applies computational thinking (abstraction, automation, analysis) to explain and enhance interaction between a user and a system. It is underpinned by modelling which admits formal reasoning, and which is amenable to computational approaches.\n",
    "\n",
    "\n",
    "<img src=\"imgs/comp_interaction_book.jpg\">\n",
    "\n",
    "*[Edited by Antti Oulasvirta, Per Ola Kristensson, Xiaojun Bi, and Andrew Howes]*\n",
    "\n",
    "\n",
    "Computational interaction draws on insight from:\n",
    "* machine learning;\n",
    "* signal processing;\n",
    "* information theory;\n",
    "* optimisation;\n",
    "* Bayesian inference;\n",
    "* control theory;\n",
    "* and formal modelling.\n",
    "\n",
    "It emphasises generating motor themes in HCI, and robust, replicable and durable approaches which go beyond point sampling of the interaction space.\n",
    "\n",
    "### Computational interaction would typically involve at least one of:\n",
    "* I. an explicit mathematical model of user-system behavior;\n",
    "* II. a way of updating that model with observed data from users;\n",
    "* III. an algorithmic element that, using this model, can directly synthesise or adapt the\n",
    "design;\n",
    "* IV. a way of automating and instrumenting the modeling and design process;\n",
    "* V. the ability to simulate or synthesise elements of the expected user-system behavior.\n",
    "\n",
    "Computational interaction often involves elements from machine learning, signal processing, information theory,\n",
    "optimisation, inference, control theory and formal modelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Interaction\n",
    "\n",
    "A Bayesian:\n",
    "\n",
    "* Represents belief using probability distributions\n",
    "* Updates belief using Bayes' Rule, combining a prior belief with observed evidence\n",
    "* Infers conditional distributions over unseen parameters \n",
    "\n",
    "View: we don't know what the world is like, but we can write down a model that describes how it might behave -- a simulation that could generate data -- characterised by a collection of parameters. Given some idea about what values parameters could take on, expressed as a (prior) probability distribution, we can then use evidence observed to concentrate belief on more likely parameter configurations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian methods in HCI\n",
    "\n",
    "Bayesians use probability to describe beliefs about the world. Bayesian methods have application throughout virtually of all of HCI, but are often only encountered in a few specialised niches; for example in speech recognition. There are a wide variety of areas where Bayesian methods can be directly *used* in HCI, three of the most obvious being:\n",
    "\n",
    "* **Bayesian methods in empirical analysis** (i.e. Bayesian statistics for experiments): Bayesian analysis offers a potentially superior way of analysing some kinds of quantitative experimental work that arise in HCI. It can directly answer questions of interest, and can incorporate first-principles models from domain experts. There are opportunities for novel experimental designs (e.g. online Bayesian experimental design) and meta-analyses that can offer insights into interaction problems. The advance of easy-to-use packages for Bayesian inference (e.g. Stan) makes this practical for researchers.\n",
    "\n",
    "<img src=\"imgs/ymxc_stochastic.png\">\n",
    "<img src=\"imgs/sampled_posterior_predictive.png\">\n",
    "\n",
    "* **Bayesian methods in optimisation**: Bayesian optimisation can be used to optimise functions which are not easy to evaluate, or are noisy to evaluate, for example using Gaussian Processes as proxy functions. This is typically the case in optimisation with observations from users, who are expensive to measure, noisy and not governed by simple mathematical formulae. This can range from simple Bayesian A/B testing to sophisticated modelling of user behaviour at a fine level of granularity. Bayesian optimisation can be applied to a huge range of problems with expensive or noisy functions, from inferring subjective preferences to optimising touch sensor configurations.\n",
    "\n",
    "<img src=\"imgs/bayesian_optimization.jpeg\"> \n",
    "\n",
    "*[From the emukit documentation: https://amzn.github.io/emukit/bayesian-optimization/]*\n",
    "\n",
    "* **Bayesian methods in input decoding**: Bayesian methods can be used to represent the problem of the interface itself -- how does information flow from human to computer? This can be used to derive robust models based around inference of intention. Strong prior models of what we expect users to do allow us to extract maximum value from user actions and preserve and use uncertainty about user intent. This is a philosophy of interaction founded in the idea of the interface as a concentrator of belief, whose mechanics are driven by the logic of probability.\n",
    "\n",
    "<img src=\"imgs/capture.png\" width=\"50%\">\n",
    "\n",
    "*[Bayesian inference of gesture recognition]*\n",
    "\n",
    "\n",
    "There are other topics where Bayesian ideas have bearing on problems in interaction design, including:\n",
    "* **Interaction with Bayesian models**, that is how to explain, explore, understand and make help users make rational decisions with probabilistic computational models (see e.g. [Explorable Multiverse Analyses](https://explorablemultiverse.github.io/)). This is a problem of communicating distributions from systems to users.\n",
    "\n",
    "* **Bayesian models of human behaviour** which seek to explain user behaviour, from low-level motor actions and perceptual functions through to decision making as approximate Bayesian inference. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian filtering for intention inference\n",
    "\n",
    "#### Inferring user intention in a noisy world\n",
    "----\n",
    "\n",
    "    All theorems are true. \n",
    "    All models are wrong. \n",
    "    And all data are inaccurate. \n",
    "\n",
    "    What are we to do? \n",
    "    We must be sure to remain uncertain.\n",
    "\n",
    "-- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic purpose\n",
    "\n",
    "This section will cover probabilistic **inference**. Rather than learning a single set of parameters by optimisation, we can infer probability distributions over possible configurations of models that might be compatible with our data. Our \"models\" will be representations of user intentions, and the processes that transduce intention into sensor measurement.\n",
    "\n",
    "We will develop the idea of **probabilistic filtering** to rigorously define the interaction problem as online probabilistic inference over time, and derive practical algorithms that can be fuse together input device signals across time and across sensors channels. This will give us a robust, theoretically underpinned way of combining together sensing into estimates of intention.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this relevant for computational HCI?\n",
    "* We will build **statistical models** of user behavior, and estimate parameters of that model from quantitative observations of data. \n",
    "* This is a **model-led approach** which has a rich mathematical underpinning and many powerful algorithmic tools which can be brought to bear.\n",
    "* This is **robust** (it appropriately represents uncertainty) and **generative** (it can simulate behaviour compatible with observations).  \n",
    "* There is an extensive mathematical framework to support our interfaces, as well as powerful software tools to implement these ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of this module [80 minutes]\n",
    "\n",
    "### Interaction is inference\n",
    "* Show how to represent interaction problems as inference and discuss how probabilistic filters can be used to attack these inference problems \n",
    "* Discuss *alternative* approaches to solving interaction problems (what would you do if you were not Bayesian?)\n",
    "\n",
    "\n",
    "### Probability refresher\n",
    "* Introduce random variables and distributions \n",
    "* Outline Bayesian inference \n",
    "* Show how Bayesian inference can be used to fuse data across time and across sensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Probabilistic filters\n",
    "* Introduce the basic terminology for probabilistic filters\n",
    "* Discuss principles behind probabilistic tracking of belief \n",
    "* Discuss how to frame HCI problems in terms of probabilistic filtering\n",
    "* Practical example of tracking with probabilistic filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "# Principles \n",
    "-------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> Interaction is the process of driving a system into a state compatible with user intentions.\n",
    "\n",
    "<img src=\"imgs/brainspace.png\" width=\"100%\">\n",
    "\n",
    "Note that we focus here on the problem of **input**; getting a computer to do what we want. We will touch on the problem of **feedback** where we aligning users with the processes mediating this input using some form of display. However, we will not consider the **display** problem, where we try to efficiently inject information from a computer into a user's mind.\n",
    "\n",
    "\n",
    "There are many perspectives on interaction that arise from this stance, including:\n",
    "\n",
    "| Perspective   | Burden | Characteristic                         |\n",
    "|---------------|--------|----------------------------------------|\n",
    "| Communication | User   | User gets information into the system, by encoding intentions. |\n",
    "| Control       | Split  | User drives state towards intention via feedback control.   |\n",
    "| Inference     | System | System infers what user intention is from sensed user actions. |\n",
    "\n",
    "### Interaction as inference\n",
    "If we view interaction as inference of intention, there are three elements:\n",
    "* **Interaction is inference**; it is the process of inferring a distribution over a hidden variable: what the user wants a system to do. \n",
    "* **Observations are noisy and incomplete** What a system sees is a distorted and incomplete representation of user actions in the world, which are in turn a noisy representation of internal intentions (your hand does not always go where you want it...)\n",
    "* **Interaction occurs over time** Interaction is a *process* that evolves over time. Information flow is not instantaneous. Observations must be fused together to update a beliefs.\n",
    "\n",
    "### Optimal mindreading\n",
    "We'll look at a **Bayesian** approach to modelling human computer interaction, where we explicitly model what might be going on inside a user's mind and use Bayesian methods to try and perform \"optimal mindreading\".\n",
    "\n",
    "<img src=\"imgs/brain_inference.png\">\n",
    "\n",
    "# Interaction as inference\n",
    "One view on interaction is to see user intentions as **unknown values** which are partially observed through input sensors. The time series of inputs from the user only give a partial, noisy, incomplete view of intention inside the user's head. We try and explain what is going on inside a user using a *generative model* which is a simplified representation of what goes on inside a user's head and how it is mediated and transformed by the world. The better model we have available, the more effectively we can infer intention.\n",
    "\n",
    "> In this view, improving interaction (or at least *input*) comes down to more efficiently concentrating probability density where a user wants it. A better pointing device reduces uncertainty faster; a better display helps a user understand how best to target future actions to concentrate belief as desired; a better model of the user intentions concentrates belief with less explicit effort on the part of a user.\n",
    "\n",
    "<img src=\"imgs/contraction_probability.png\">\n",
    "\n",
    "\n",
    "\n",
    "#### Partitioning the inferred variables\n",
    "We can further partition the problem. The causes of observed evidence can be factored: for example, into:\n",
    "* The parameters of the intentions that generate the behaviour\n",
    "* The parameters of the motor system that generate movement, conditioned on intention\n",
    "* The parameters of the sensing system that generates signals, conditioned on motor action\n",
    "\n",
    "$$P(X_{\\text{intention}}, X_{\\text{motor}}, X_{\\text{sensing}}|Y)$$\n",
    "\n",
    "[Betancourt's article on probabilistic modeling](https://betanalpha.github.io/assets/case_studies/modeling_and_inference.html) expresses these ideas in terms of the \"phenomenon\" (intention), \"environment\" (motor/world system) and \"probe\" (sensing/interface context)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Probabilistic filtering\n",
    "We'll specifically look at probabilistic filtering, which is just Bayesian updating over time. There are a collection of algorithms for doing so efficiently.  Probabilistic filtering **(PF)** tracks the evolution of some unknown variables *[user intentions]* given observed evidence *[user input]*, in a way that is **robust**. Probabilistic filters infer a **distribution** over possible hidden (unobserved) variables, updating them over time. These filters are:\n",
    "* inherently **uncertain**, as they represent degrees of belief as probability distributions over states\n",
    "* and **dynamic**, as they explicitly model changing state over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Properties\n",
    "Probabilistic filtering is:\n",
    "\n",
    "| Property | Why  |\n",
    "|----------|------|\n",
    "|**Bayesian**  |  Represents degrees of belief using probability distributions.    |\n",
    "|**predictive**  |  Works by comparing predictions with reality.   |\n",
    "|**generative** |  Involves generating (i.e. simulating) behavior.   |\n",
    "\n",
    "-----\n",
    "Probabilistic filtering is an **inverse probability** approach, and it requires that we think of interaction from an unique perspective. We have to explicitly be able to write down:\n",
    "\n",
    "* what we want to know (i.e. the **state space of intention**), which describes intentions that might give rise to observed behaviour;\n",
    "* how that will change over time (i.e. the **dynamics of intention**);\n",
    "*  a model that *if we knew what the user intention was, what the expected behavior would be* (i.e. a **generative function mapping intention -> expected user inputs as observed by a sensor**).\n",
    "\n",
    "Note that this is the **inverse** of the typical way of approaching this problem, where we would try and find a mapping from a sensors to intention, by design or by learning. Instead, we propose that we can postulate intentions, and look for evidence that might favour some underlying intentions over others. This can be a subtle and powerful way of distinguishing intentions who are poorly represented in observed signals.\n",
    "\n",
    "\n",
    "### Simulation viewpoint\n",
    "These filters are really *simulators*. They *simulate* how possible user behaviors might unfold over time. In some probabilistic filters, hundreds of parallel simulators are run, each with slightly different parameters. In all cases, the simulations are adjusted online to better match observed reality. The internal parameters that drive the simulation are the *unknown variables* we want to infer and the *evidence* is the observed reality that adjusts the simulation parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is this computational HCI?\n",
    "Probabilistic filtering means writing down an **executable, statistical model** of user behavior, then **running an inference algorithm** that updates beliefs based on the way observations evolve. The **parameters** of the filter can be **learned from user data**. The effectiveness of the filter can be quantitatively measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### What are competitive approaches?\n",
    "#### **Crafted mappings**\n",
    "**where we try to find (by hand) transforms from sensors to intentions that are  simple or obvious.**\n",
    "\n",
    "**Example:** a button, which has two physical states, and maps on to two intentional states via two electrical states. Pushed down = current flows = user intended to switch on. The mapping from electrical states to intentional states is **designed.**\n",
    "\n",
    "This is is explicit design, which often puts the burden of mapping states <=> intentions on the user. Users have to learn to encode their intentions in physical actions which hopefully correspond \"intuitively\" with the crafted mappings that have been set up to detect them.\n",
    "\n",
    "<img src=\"imgs/undo.jpg\">\n",
    "\n",
    "*[Image credit: David Singleton via flickr.com CC-BY 2.0]*\n",
    "\n",
    "#### **Machine learned mappings**\n",
    "**where we train a system to recognize a class of input patterns as being representative of an intended behavior.**\n",
    "\n",
    "**Example:** Finger gesture recognizer; hundreds of examples of many users performing one of N multi-touch gestures are recorded. These are used to train a random forest to classify the intended gesture. The mapping from electrical states (capacitive sensors) to intentional states is **learned**.\n",
    "\n",
    "This reduces the burden on the user to learn a specific mapping and instead adapts to behaviours exhibited by real users with real input devices. But it can suffer with issues in generalisation and robustness, and is often very hard to combine with known first-principles models (e.g. users can't change the size of their fingers!)\n",
    "\n",
    "<img src=\"imgs/svm.jpg\" width=\"300px\">\n",
    "\n",
    "*[Image credit: Elisfm - via Wikimedia Commons; public domain]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Benefits of a probabilistic filtering approach\n",
    "\n",
    "Probabilistic filtering has a number of motivating properites that make it worth studying:\n",
    "\n",
    "### Stronger modelling\n",
    "* **Easy to incorporate priors** Prior knowledge is naturally and easily expressed. We write down a \"simulator\" that behaves  according to mechanics we can arbitrarily define and can build upon what we know about the world.\n",
    "* **Flexible modeling** PFs can incorporate both fundamental modeling (e.g. physiological or cognitive models) and data-driven machine learning.\n",
    "* **Easy to balance modelling with learning** We can fuse both learned components with prior models, either to efficiently emulate complex processes via learned surrogates, or to capture models for which we lack strong first-principles views.\n",
    "\n",
    "### Robust\n",
    "* **Robustness to noise** PFs can work well even with input sensors that are noisy.\n",
    "* **Robustness to poorly specified models** PFs can cope predictably even if our models are bad.\n",
    "* **Robustness to intermittence** PFs can continue to sensibly interpolate when input cuts out.\n",
    "\n",
    "### Decoupled\n",
    "\n",
    "* **Decoupled from real-time** PFs can infer past (smoothing), present (filtering) and future (forecasting).\n",
    "* **Inherent fusion of multiple input sensors** PFs are often used to solely to fuse together multiple inputs from different sensors.\n",
    "\n",
    "### Reflective\n",
    "* **Uncertainty estimates** PFs *know how certain they are* and this can be used in the interaction design.\n",
    "* **Better feedback** PFs  offer the opportunity to give users rich insight into the process of intention decoding.\n",
    "\n",
    "---\n",
    "\n",
    "## Drawbacks\n",
    "\n",
    "* Computational demands can be heavy, especially compared to black box prediction models.\n",
    "* Speeding up inference may require more sophisticated statistical models, and this can get tricky quickly.\n",
    "* If you **don't** have good models, then it may be easier to just learn from data, or force users to adapt to a design.\n",
    "* Distributions are not natural for users. Representing these so users understand what is going on can be tricky.\n",
    "* Rules have to be defined to turn inference into action, typically involving some form of utility function to make decisions. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "# Probability refresher\n",
    "\n",
    "## Random variables and distributions\n",
    "A **random variable** $X$ is a variable that can take on different values, but we do not know what value it has; i.e. one that is \"unassigned\". However, we have knowledge which captures the possible states the variable could take on, and their corresponding probabilities, which is encoded in the **distribution** of that variable. Probability theory allows us to manipulate random variables without having to assign them a specific value.\n",
    "\n",
    "A random variable might represent:\n",
    "\n",
    "* the outcome of dice throw (discrete), i.e. over the set of outcomes $\\{1,2,3,4,5,6\\}$; \n",
    "* whether or not it is raining outside (discrete: binary), over the set of outcomes $\\{\\text{heads}, \\text{tails}\\}$; \n",
    "* the height of person we haven't met yet (continuous), over the set of outcomes $\\real$; \n",
    "* the position of a user's hand (continuous, multi-dimensional), over the set of outcomes $\\real^3$. \n",
    "\n",
    "## Distributions\n",
    "A **probability distribution** defines how likely different states of a random variable are. \n",
    "\n",
    "We can see $X$ as the the *experiment* and $x$ as the *outcome*, with a function mapping every possible outcome to a probability. We write $P(x)$ to mean the probability of $P(X=x)$ (note the case!), that is that $X$ takes on a value $x$.\n",
    "\n",
    "$$P(X=x),\\  \\text{the probability of random variable X taking on value x}\\\\\n",
    "P(X),\\  \\text{shorthand for probability of X=x }\\\\\n",
    "P(x),\\  \\text{shorthand for probability of specific value X=x }\\\\\n",
    "$$\n",
    "\n",
    "### Discrete and continuous\n",
    "\n",
    "The function defining the distribution maps the outcomes of a random variables to real numbers (probabilities) in the range $[0,1]$, subject to the constraint that the sum of all probabilities across all outcomes. These probabilities, in a Bayesian world view, represent belief about how likely different outcomes are. Distributions are defined by functions $f_X(x)$, which give the probability of an outcome $x$ (imagine a dictionary mapping outcomes to probabilities). For technical reasons, these are distinguished for continuous and discrete variables:\n",
    "\n",
    "* **probability mass function** (PMF),  for discrete variables\n",
    "* **probability density functions** (PDF),  for continuous variables\n",
    "\n",
    "## Samples and sampling\n",
    "**Samples** are observed outcomes of an experiment; we will use the term **observations** to refer to the same thing when samples come from measurements, rather than being simulated. We can **sample** from a distribution; this means simulating outcomes according to the probability distribution of those variables. \n",
    "\n",
    "For discrete random variables, this is easy: we simply produce samples by drawing each outcome according to its probability. (For continuous variables, we need to use specific algorithms to draw samples according to a distribution.)\n",
    "\n",
    "## Random variables\n",
    "\n",
    "* Defined over a set of outcomes (e.g. `{heads, tails}` or the real numbers, or the set of `[longitude, latitude, altitude]` tuples, etc.)\n",
    "* Defined by a function: probability mass/density function, which maps each outcome to a \"belief weight\" (probability) such that the integral/sum of all weights is 1.0\n",
    "* Key operations:\n",
    "    * **Likelihood**, which just evaluates the density/mass function at some value, i.e. evaluating $f_X(x)$ or $P(X=x)$ at some known $x$. We typically want to be able to compute the *log-likelihood*, as a more computationally useful form.    \n",
    "    * **Sample**, simulating an example from a random variable, i.e. drawing a new random $x$ such that the long-term distribution of many such samples follows the distribution that defines the random variable.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We usually want to be able to apply these operations to many values at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A definition of a probabilty distribution in Python\n",
    "\n",
    "class DiscreteRandomVariable:\n",
    "    def __init__(self, pmf):\n",
    "        self.pmf = pmf        \n",
    "        \n",
    "        self.p = np.array(list(pmf.values()))\n",
    "        # cumulative probabilities of outcomes \n",
    "        self.cmf = np.cumsum(self.p)        \n",
    "        # list of outcomes, in same order as CMF\n",
    "        self.outcomes = list(pmf.keys())\n",
    "\n",
    "    def lik(self, outcome):          \n",
    "        \"\"\"Return the likelihood of some outcome\"\"\"\n",
    "        return self.pmf[outcome]\n",
    "\n",
    "    def sample(self, n):\n",
    "        \"\"\"Draw a random sample from this random variable\"\"\"         \n",
    "        return [self.outcomes[s] for s in np.digitize(np.random.uniform(0,1,n), self.cmf)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "['tails', 'tails', 'heads', 'tails', 'tails', 'heads', 'tails', 'tails', 'tails', 'heads', 'tails', 'heads', 'tails', 'heads', 'tails', 'tails', 'tails', 'tails', 'heads', 'tails', 'tails', 'tails', 'tails', 'heads', 'heads', 'heads', 'tails', 'tails', 'tails', 'heads']\n"
     ]
    }
   ],
   "source": [
    "coin = DiscreteRandomVariable({\"heads\":0.5, \"tails\":0.5})\n",
    "print(coin.lik(\"heads\"))\n",
    "print(coin.sample(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinations of random variables\n",
    "\n",
    "We can join and split random variables into joint and marginal mass functions:\n",
    "\n",
    "* **Joint probability mass function** of *N* random variables, formed by the Cartesian product of the outcomes, assigned the product of the probabilities: $$P(X,Y)$$\n",
    "\n",
    "* **Marginal probability mass function** from a joint mass function to a single (or reduced) mass function, by summing over one variable: $$P(X) = \\sum_Y P(X,Y)$$ \n",
    "\n",
    "* **Conditional probability mass function** from a joint probability mass function $$P(X|Y) = \\frac{P(X,Y)}{P(Y)}$$\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-5-1a4dd07f3dcf>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-1a4dd07f3dcf>\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    def __or__(self, other):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class MultiRandomVariable:\n",
    "    \n",
    "    def __init__(self, pmf):        \n",
    "        self.pvars = [DiscreteRandomVariable(pmf)]\n",
    "        \n",
    "    def lik(self, *outcomes):\n",
    "        return np.prod([pvar.lik(outcome) for pvar, outcome in zip(self.pvars, outcomes)])\n",
    "    \n",
    "    def sample(self, n):\n",
    "        return list(zip(*[pvar.sample(n) for pvar in self.pvars]))\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        ret = MultiRandomVariable({})\n",
    "        ret.pvars = self.pvars + other.pvars\n",
    "        return ret        \n",
    "        \n",
    "    def __index__(self, ix):\n",
    "        # marginalise to a single variable\n",
    "        for i, pvar in enumerate(self.pvars):\n",
    "            if i!=ix:\n",
    "                \n",
    "    \n",
    "    def __or__(self, other):\n",
    "        # condition on a random variable\n",
    "        pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiRandomVariable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b70a053498e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcoin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiRandomVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"heads\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tails\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiRandomVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m6.0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdicecoin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdice\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcoin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdicecoin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlik\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"heads\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultiRandomVariable' is not defined"
     ]
    }
   ],
   "source": [
    "coin = MultiRandomVariable({\"heads\":0.5, \"tails\":0.5})\n",
    "dice = MultiRandomVariable({i:1/6.0 for i in range(1,7)})\n",
    "dicecoin = dice * coin\n",
    "print(dicecoin.lik(5, \"heads\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this basic idea, we can derive many operations:\n",
    "    \n",
    "* **Expectation** An \"average\" of a *function* of a random variable. This can be evaluated exactly by integrating over all possible outcomes, and computing the probability of that outcome times the function of that outcome. \n",
    "$$\\mathbb{E}[f(X)] = \\int_x P(X=x) f(x)dx$$\n",
    "\n",
    "* **Monte Carlo approximation to the expectation**\n",
    "    Can be computed **approximately** from many samples $x^{(1)}, x^{(2)}, x^{(3)}, \\dots$ from $X$ using\n",
    "\n",
    "    $$\\mathbb{E}[f(X)] \\approx \\frac{1}{N} \\sum_i P(X=x^{(i)}) f(x^{(i)})dx$$\n",
    "\n",
    "* **Joint likelihood** of multiple **independent** outcomes; just the product of the likelihoods: $$\\mathcal{L}(x_1, x_2, \\dots) = \\prod_i \\mathcal{L}(x_i) = \\prod_i P(X=x_i)$$\n",
    "\n",
    "* **Log-likelihood** Just the logarithm of the likelihood, typically used for numerical convenience, as we can then sum together log-likelihoods, instead of multiplying (small) likelihood values.\n",
    "\n",
    "$$\\log \\mathcal{L}(x_1, x_2, \\dots) = \\log \\prod_i P(X=x_i) = \\sum_i \\log \\mathcal{L}(x_i) $$\n",
    "\n",
    "* **Entropy** Just the expectation of the (negative) log-likelihood; measures the \"spread\" or \"confusion\" of a random variable. $$H(X) = \\mathbb{E}[-\\log P(X=x)] = -\\int_x P(X=x) \\log P(X=x) = -\\int_x P(x) \\log P(x)$$\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DRandomVariable(DiscreteRandomVariable):\n",
    "                \n",
    "        def joint_lik(self, outcomes):\n",
    "            \"\"\"Compute the probability of a set of independent outcomes being observed.\"\"\"\n",
    "            return np.prod([self.lik(outcome) for outcome in outcomes])\n",
    "\n",
    "        def entropy(self):\n",
    "            \"\"\"Return the entropy of this random variable\"\"\"\n",
    "            p = np.array(list(self.pmf.values()))\n",
    "            return -np.sum(p * np.log(p)/np.log(2))\n",
    "        \n",
    "        def joint_llik(self, outcomes):\n",
    "            \"\"\"Return the joint log-likelihood of several outcomes; we would usually define this differently\n",
    "            and obtain the log likelihood *directly* and never use a lik() function, but\n",
    "            this is convenient for explanation.\"\"\"\n",
    "            return np.sum((np.log(self.pmf[outcome]) for outcome in outcomes))\n",
    "        \n",
    "        def expectation(self, fn):\n",
    "            \"\"\"Return the average value of fn applied to this random variable,\n",
    "            by summing the products of the function applied to each value and the\n",
    "            corresponding probability\"\"\"\n",
    "            return sum(fn(outcome)*p for outcome, p in self.pmf.items())\n",
    "\n",
    "        def mc_expectation(self, fn, n):\n",
    "            \"\"\"Approximate an expectation using Monte Carlo; i.e. sample a bunch of examples\n",
    "            and then compute the average value of those samples. This works even if we\n",
    "            can't evaluate the probability distribution everywhere (e.g. because it is infinite).\"\"\"\n",
    "            return np.mean([fn(sample) for sample in self.sample(n)])\n",
    "        \n",
    "               \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to model simple random systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of HHH 0.125\n",
      "Log-likelihood of HHH -2.0794415416798357\n",
      "Sample of coin tosses ['tails', 'tails', 'tails', 'tails', 'tails']\n",
      "Entropy of coin tosses (bits) 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n"
     ]
    }
   ],
   "source": [
    "coin = DRandomVariable({\"heads\":0.5, \"tails\":0.5})\n",
    "print(\"Likelihood of HHH\", coin.joint_lik([\"heads\", \"heads\", \"heads\"]))\n",
    "print(\"Log-likelihood of HHH\", coin.joint_llik([\"heads\", \"heads\", \"heads\"]))\n",
    "print(\"Sample of coin tosses\", coin.sample(5))\n",
    "print(\"Entropy of coin tosses (bits)\", coin.entropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute expectations under utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation under value_fn 2.5\n",
      "Approx. expectation under value_fn 2.7\n"
     ]
    }
   ],
   "source": [
    "# this is an arbitrary function that gives 5 \"points\" for a heads, and 0 points for\n",
    "# a tails\n",
    "def value_fn(toss):\n",
    "    return 5.0 if toss==\"heads\" else 0.0\n",
    "\n",
    "print(\"Expectation under value_fn\", coin.expectation(value_fn))\n",
    "print(\"Approx. expectation under value_fn\", coin.mc_expectation(value_fn, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we can we do with this?\n",
    "\n",
    "* We can **simulate** using the ability to *sample* from a distribution.\n",
    "* We can **evaluate** using the ability to compute likelihoods of observations.\n",
    "* We can **score** using the ability to compute expectations of functions of outcomes.\n",
    "\n",
    "### Applying functions to samples\n",
    "The use of **samples** to approximate distributions will be central to the approach we will discuss. Since samples are just ordinary values, we can apply any standard functions to them and produce new samples. This has two particular applications:\n",
    "\n",
    "* If we have samples over a distribution over beliefs *now*, we can define a prediction function that moves the predictions to a time step in the future. We can use this to introducte **dynamics**.\n",
    "\n",
    "* If we have samples over internal states, and a model of these internal states become observations, we can define an observation function, that will predict what we expect to observe. We can use this (in combination with some scoring function) to compute the likelihood of hidden states given observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions over vector spaces\n",
    "Continuous distributions generalise discrete variables (probability mass functions) (e.g. over $\\mathbb{Z}$) to continuous spaces over $\\real$ via probability density functions. \n",
    "\n",
    "Probability densities can be further generalised to vector spaces, particularly to $\\real^n$. This extends PDFs to assign probability across an entire vector space, under the constraint that the (multidimensional integral) $$\\int_{x\\in\\real^n} f_X (x) =1, x \\in \\real^n.$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal distributions\n",
    "The normal distribution is very widely used as the distribution of continuous random variables. It can be defined for a random variable of *any dimension* (a distribution over any real vector space, including infinite ones!); a **multivariate normal** in statistical terminology.\n",
    "\n",
    "A multivariate normal is fully specified by a **mean vector** $\\vec{\\mu}$ and a **covariance matrix** $\\Sigma$. If you imagine the normal distribution to be a ball shaped mass in space, the mean *translates* the mass, and covariance applies a *transformation* matrix (scale, rotate and shear) to the ball to stretch it out into an ellipse. All normal distributions have an elliptical shape with highest density at the mean and falling off towards the edges.\n",
    "\n",
    "We can now talk about the **joint probability density** (density over all dimensions) and the **marginal probability density** (density over some sub-selection of dimensions).\n",
    "\n",
    "For example, consider $X \\sim N(\\vec{\\mu}, \\Sigma), X \\in \\real^2$, a two dimensional (\"bivariate\") normal distribution. It has a distribution $P(X_0,X_1)$  or $P(X,Y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c1bc10ddc5ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mdemo_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Unit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "def demo_normal(ax, mean, cov, title):\n",
    "    x,y = np.meshgrid(np.linspace(-3,3,50), np.linspace(-3,3,50))\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:,:,0] = x\n",
    "    pos[:,:,1] = y\n",
    "    joint_pdf = scipy.stats.multivariate_normal.pdf(pos, mean, cov)\n",
    "    ax.pcolor(x,y,joint_pdf, cmap='viridis', vmin=0, vmax=0.25)\n",
    "    \n",
    "    ax.axhline(0, color='C1', linewidth=0.2)\n",
    "    ax.axvline(0, color='C1', linewidth=0.2)\n",
    "    ax.text(0, 3.2, title, ha='center')\n",
    "    ax.axis(\"off\")\n",
    "    ax.axis(\"image\")\n",
    "    \n",
    "    \n",
    "fig = plt.figure()  \n",
    "ax = fig.add_subplot(2,3,1)\n",
    "demo_normal(ax, [0,0], [[1,0],[0,1]], \"Unit\")    \n",
    "ax = fig.add_subplot(2,3,2)\n",
    "demo_normal(ax, [0,0], [[0.25,0],[0,0.25]], \"Tighter\")    \n",
    "ax = fig.add_subplot(2,3,3)\n",
    "demo_normal(ax, [1,-0.5], [[2,0],[0,2]], \"Off-centre\") \n",
    "ax = fig.add_subplot(2,3,4)\n",
    "demo_normal(ax, [0,0], [[2,0],[0,1]], \"Stretched\") \n",
    "ax = fig.add_subplot(2,3,5)\n",
    "demo_normal(ax, [0,0], [[2,0.1],[1,1]], \"Skewed\") \n",
    "ax = fig.add_subplot(2,3,6)\n",
    "demo_normal(ax, [0,0], [[2,-0.9],[0.4,0.2]], 'Skewed') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint, conditional, marginal\n",
    "\n",
    "The **joint probability** of two random variables is written $$P(X,Y)$$ and gives the probability that $X$ and $Y$ take the specific values *simultaneously* (i.e. $P(X=x) \\land P(Y=y)$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **marginal probability** is the derivation of $P(X)$ from $P(X,Y)$ by integrating (summing) over all the possible outcomes of $Y$:\n",
    "$$P(X) = \\int_y P(X,Y=y) dy\\  \\text{for a PDF.}$$\n",
    "$$P(X) = \\sum_y P(X,Y=y)\\  \\text{for a PMF.}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marginalisation** just means integration over one or more variables from a joint distribution: it *removes* those variables from the distribution.\n",
    "\n",
    "Two random variables are **independent** if the they do not have any dependence on each other. If this is the case then the joint distribution is just the product of the individual distributions:\n",
    "$P(X,Y) = P(X)P(Y).$ This is not true in the general case where the variables have dependence.\n",
    "\n",
    "The **conditional probability** of $X$ *given* $Y$ is written as $$P(X|Y)$$ and can be computed as $$\\begin{equation} P(X|Y) = \\frac{P(X,Y)}{P(Y)}. \\end{equation}$$ This tells us how likely $X$ is to occur *if we already know*  (or fix) the value of $Y$.\n",
    "\n",
    "Because we can see a distribution over $R^2$ as a distribution over two variables $X$ and $Y$, we can talk about things like marginalising normal distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d35ccd42b97d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmarginal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoint_pdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjoint_pdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpcolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjoint_pdf\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmarginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'viridis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mjoint_marginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-d35ccd42b97d>\u001b[0m in \u001b[0;36mjoint_marginal\u001b[1;34m(cov)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mjoint_pdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# plot the joint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def joint_marginal(cov):\n",
    "    # create an independent 2D normal distribution\n",
    "    x,y = np.meshgrid(np.linspace(-3,3,50), np.linspace(-3,3,50))\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:,:,0] = x\n",
    "    pos[:,:,1] = y\n",
    "    joint_pdf = scipy.stats.multivariate_normal.pdf(pos, [0,0], cov)\n",
    "    fig = plt.figure()\n",
    "    # plot the joint\n",
    "    ax = fig.add_subplot(2,2,1)\n",
    "    ax.axis('equal')\n",
    "    plt.title(\"Joint p(x,y)\")\n",
    "    ax.pcolor(x,y,joint_pdf, cmap='viridis')\n",
    "    # plot the marginals\n",
    "    ax = fig.add_subplot(2,2,3)\n",
    "    ax.axis('equal')\n",
    "    plt.title(\"Marginal $P(x) = \\int\\  P(x,y) dy$\")\n",
    "    ax.plot(x[0,:], np.sum(joint_pdf, axis=0))\n",
    "    ax = fig.add_subplot(2,2,2)\n",
    "    ax.axis('equal')\n",
    "    plt.title(\"Marginal $P(y) = \\int\\  P(x,y) dx$\")\n",
    "    ax.plot(np.sum(joint_pdf, axis=1), x[0,:])\n",
    "    # plot p(x|y)\n",
    "    ax = fig.add_subplot(2,2,4)\n",
    "    ax.axis('equal')\n",
    "    plt.title(\"Conditional $P(x|y) = \\\\frac{P(x,y)}{P(y)}$\")\n",
    "    marginal = np.tile(np.sum(joint_pdf, axis=0), (joint_pdf.shape[0],1))\n",
    "    ax.pcolor(x,y,joint_pdf/marginal, cmap='viridis')\n",
    "joint_marginal([[1,0],[0.5,1]])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bayesian\"> </a>\n",
    "## Probability theory and Bayesian inference\n",
    "\n",
    "#### Probability as a calculus of belief\n",
    "*Bayesians* treat probability as a **calculus of belief**; in this model of thought, probabilities are measures of degrees of belief. $P(A)=0$ means a belief that $A$ cannot be true and $P(A)=1$ is a belief that $A$ is absolutely certain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability as the optimal way of representing uncertainty\n",
    "Other representations of uncertainty are strictly inferior to probabilistic methods *in the sense that* a person, agent, computer placing \"bets\" on future events using probabilistic models has the best possible return out of all decision systems when there is uncertainty. \n",
    "\n",
    "*Bayesians* allow for belief in states to be combined and manipulated via the rules of probability. The key process in Bayesian logic is *updating of beliefs*. Given some *prior* belief (it's Glasgow, it's not likely to be sunny) and some new evidence (there seems to be a bright reflection inside) we can update our belief to calculate the *posterior* -- our new probability that it is sunny outside. Bayesian inference requires that we accept priors over events, i.e. that we must explicitly quantify our assumptions with probability distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior, likelihood, posterior, evidence\n",
    "\n",
    "We often want to know the probability of a some outcome $A$ given some other outcome $B$; that is $P(A|B)$. But we are often in the situation that we can only compute $P(B|A)$. \n",
    "\n",
    "In general $P(A|B) \\neq P(B|A);$ and the two expressions can be completely different. \n",
    "\n",
    "Typically, this type of problem occurs where we:\n",
    "* want to know the probability of some event given some *evidence* \n",
    "* but we only know the probability of the evidence given the event \n",
    "\n",
    "**Bayes' rule** gives a consistent way to invert the probability distribution:\n",
    "$$ \\begin{equation} P(A|B) = \\frac{P(B|A) P(A)}{P(B)} \\end{equation}$$\n",
    "\n",
    "This follows directly from the axioms of probability. Bayes' Rule is a very important rule, and has some surprising results.\n",
    "\n",
    "* $P(A|B)$ is called the **posterior** -- what we want to know, or will know after the computation\n",
    "* $P(B|A)$ is called the **likelihood** -- how likely the event $A$ is to produce the evidence we see\n",
    "* $P(A)$ is the **prior**  -- how likely the event $A$ is regardless of evidence\n",
    "* $P(B)$ is the **evidence** -- how likely the evidence $B$ is regardless of the event.\n",
    "\n",
    "Bayes' rule gives a consistent rule to take some prior belief and combine it with observed data to estimate a new distribution which combines them.\n",
    "\n",
    "We often phrase this as some **hypothesis** $H$ we want to know, given some **data** $D$ we observe, and we write Bayes' Rule as:\n",
    "$$ \\begin{equation}P(H|D) = \\frac{P(D|H) P(H)}{P(D)} \\end{equation}$$\n",
    "\n",
    "(the probability of the hypothesis given the data) is equal to (the probability of the data given the hypothesis) times (the probability of the hypothesis) divided by (the probability of the data).\n",
    "\n",
    "In other words, if we want to work out how likely a hypothesis is to be true given observations, but we only know how likely we are to have seen those observations if that hypothesis *was* true, we can use Bayes' rule to solve the problem.\n",
    "\n",
    "## Bayesian interaction\n",
    "\n",
    "If we look at the problem of **inferring intent**, then:\n",
    "\n",
    "* We have **evidence** from input devices (e.g. a sequence of mouse movements)\n",
    "* We have **prior distribution** over a space of intentions\n",
    "* We want to infer the **posterior** distribution over intentions, conditioned on the observed evidence.\n",
    "\n",
    "In other words -- what was the user trying to do, given what we've observed them doing? One particularly powerful part of this is the **prior** distribution, which can be something which is **updated**; where we update belief in one timestep to produce a distribution in the next timestep, and carry on doing so recursively. The posterior at one step becomes the prior at the next; we can *accumulate* evidence.\n",
    "\n",
    "<a id=\"combining\"> </a>\n",
    "## Bayes' rule for combining evidence\n",
    "Bayes' rule is the (only) correct way to combine prior belief and observation to update beliefs. This can be used to \"learn\", where \"learning\" means updating a probability distribution based on observations. It has enormous applications anywhere uncertain information must be fused together, whether from multiple sources (e.g. sensor fusion) or over time (e.g. probabilistic filtering). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.stats\n",
    "\n",
    "def prior_posterior(prior_mean=0, prior_std=1, sonar_std=1, n=10, anim=False):\n",
    "    mean = prior_mean\n",
    "    std = prior_std\n",
    "    var = std*std\n",
    "    prior = scipy.stats.norm(mean,std)\n",
    "    evidence = scipy.stats.norm(1, 0.25)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    xs = np.linspace(-5,5,200)\n",
    "    ax.fill_between(xs, prior.pdf(xs), label=\"Prior belief\", alpha=0.3)\n",
    "    ax.fill_between(xs, evidence.pdf(xs), label=\"True generating PDF\", alpha=0.3)\n",
    "    \n",
    "    sample_var = sonar_std**2 # the *expected* variance of our observations\n",
    "    # note that changing this allows us to continously adjust our belief\n",
    "    # in our observations \n",
    "    ax.plot([0,0],[0,-0.1], 'c', alpha=0.7, label=\"Evidence\")\n",
    "    ax.plot([0,0],[0,-0.1], 'k:', alpha=0.7, label=\"Posterior belief\")\n",
    "    ax.set_title(\"Recursive Bayesian estimation\")\n",
    "    \n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"PDF $f_X(x)$\")\n",
    "    ax.axvline(1.0, label='True')\n",
    "    ax.legend()\n",
    "    for i in range(n):\n",
    "        \n",
    "        sample = evidence.rvs()\n",
    "        # single step update for a normal distribution    \n",
    "        mean = (var * sample + sample_var * mean) / (sample_var + var)\n",
    "        var = (var*sample_var) / (sample_var+var)     \n",
    "        \n",
    "        sample_pdf = scipy.stats.norm(sample, sonar_std).pdf\n",
    "        \n",
    "        # plot the sample and the resulting pdf\n",
    "        ax.plot([sample,sample],[0,-0.5], 'c', alpha=0.7)\n",
    "        if anim:\n",
    "            ax.plot(xs,-sample_pdf(xs), 'c', alpha=0.25)\n",
    "        ax.plot(xs, scipy.stats.norm(mean,np.sqrt(var)).pdf(xs), 'k:', alpha=0.25)\n",
    "        if anim:            \n",
    "            time.sleep(1.0)\n",
    "            fig.canvas.draw()\n",
    "        \n",
    "        \n",
    "    ax.fill_between(xs, scipy.stats.norm(mean,np.sqrt(var)).pdf(xs), color='g', label=\"Final posterior\", alpha=0.2)\n",
    "    ax.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "prior_posterior(0,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "prior_posterior(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "prior_posterior(-3,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "prior_posterior(-3,0.5, n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic filtering\n",
    "We will use this recursive form of Bayesian updating to estimate user intentions online. This is a **probabilistic filter**, as described in the introduction.\n",
    "\n",
    "This filter maintains a state distribution, which is used as prior for the next step of estimation. Evidence is observed, and a posterior is computed; this becomes the prior for the next step, after a **prediction** step is used to align the prior with the known or estimated behaviour.\n",
    "\n",
    "Unlike other filters, such filters maintain a **distribution** over some hidden variable we are trying to estimate. This makes it possible for them to cope with noise and uncertainty robustly. It also complicates their implementation, but their are good models which are readily available.\n",
    "\n",
    "In HCI, at the very highest level, we want to estimate **intention $X_t$** given **sensor input $Y_t$** $P(X_t|Y_t)$, both of which change over time. \n",
    "\n",
    "* **Abstraction** $X_t$ might be expressed across multiple levels of abstraction. For example, \"targeting a point\", \"entering a letter\", \"entering a command\", \"opening a file\", \"rearranging a document\"\n",
    "* **Sensing** $Y_t$ might be distributed over timescales (e.g. immediate cursor information versus learned language model) and over sensor modalities (e.g. combining information from a pose sensor with microphone data to estimate surface contact events)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview diagram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/control_loop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terminology\"> </a>\n",
    "## Probabilistic filtering terminology \n",
    "\n",
    "Notation:\n",
    "* We have a sequence of states over time, indexed by $t$\n",
    "* $X_t$ the variable we want to know (at time $t$) (e.g. an intention inside a user's head). \n",
    "* $Y_t$ the variable we can observe (e.g. a sensor we can get readings from).\n",
    "* For computational simplicity, we assume **discrete time**, i.e. we observe sensors in a discrete, regularly sampled way.\n",
    "\n",
    "* We want to compute $P(X_t|Y_t)$ (the **inverse problem**). \n",
    "* We use a **forward model** $P(Y_t|X_t)$ to infer this.\n",
    "* We need to define two functions: ${\\bf\\hat{y_t}} = f({\\bf \\hat{x}}_t)$ (the **observation function**) and $\\hat{\\bf x}_{t} = g(\\hat{\\bf x}_{t-1})$ (the **dynamics** or **process function**).\n",
    "* We also need to compute the likelihood of the real observation given our model: $p(\\bf\\hat{y_t}|{\\bf y_t})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $f$, $g$ are often very simple functions.\n",
    "\n",
    "<img src=\"imgs/stochastic.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive filtering\n",
    "\n",
    "<img src=\"imgs/recursive.png\">\n",
    "\n",
    "Probabilistic filters are sometimes called **recursive Bayesian filters**. \n",
    "* They are **Bayesian** because they represent belief about states via probability distributions.\n",
    "* They are **recursive** because they take a *prior*, condition on *evidence* and compute a *posterior*; this *posterior* then becomes the *prior* at the next time step.\n",
    "\n",
    "As well as straightforward conditioning on observed evidence, probabilistic filters incorporate dynamics which form predictions of the world at the next time step.\n",
    "\n",
    "#### Predictor-corrector\n",
    "**This is a predictor-corrector model**; the dynamics model supplies predictions, and corrections to those predictions are applied by the observation model.\n",
    "\n",
    "## Uses of probabilistic filters\n",
    "Probabilistic filters are applicable in many HCI tasks, wherever there is a process evolving over time and uncertainty about what users want to do. \n",
    "\n",
    "For example, we have used them extensively to track finger configurations when using capacitive sensors. In this case, we have a finger pose state space (hidden) and a sensor matrix (observed), and the filter estimates pose in real-time.\n",
    "\n",
    "<img src=\"imgs/finger_track.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm\n",
    "We will use the **particle filter** algorithm (technically the **SIR** variant, which is the simplest to understand).\n",
    "\n",
    "A particle filter requires that we specify:\n",
    "* A **dynamics function** that predicts how we expect the world to evolve, which takes \n",
    "$\\hat{\\bf{x}}_t \\rightarrow \\hat{\\bf x}_{t+1}$\n",
    "* An **observation function** that predicts what we expect to observe, given a hypothesized state $\\hat{\\bf y}_t \\rightarrow \\hat{\\bf{x}_t}$\n",
    "* A **weight function**, that, given a hypothesized observation $\\hat{\\bf y}_t$, can be used to compute $p(\\hat{\\bf y}_t|{\\bf y}_t)$. This is performed by computing weights $w_i$ for each particle $i$ and then normalizing to produce a probability:\n",
    "$$p^{(i)}(\\hat{\\bf y}_t|{\\bf y}_t) = \\frac{w_i}{\\sum_j w_j}$$\n",
    "* A set of **prior distributions** that specify our initial guesses for $\\hat{\\bf x}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why particle filter?\n",
    "The Kalman filter uses the normal distribution to model all of the uncertainty in the system. This is great for computational efficiency, since the updates are simple linear transforms. It is also inferentially efficient; given only a small amount of evidence the Kalman filter will converge quickly compared to other approaches.\n",
    "\n",
    "But it has several significant drawbacks, which make it difficult to apply directly to infer *gestures* from observations:\n",
    "\n",
    "#### Kalman filter drawbacks\n",
    "* the **dynamics** have to be linear: we can't have complicated dynamic models (although we can linearise at each time step).\n",
    "\n",
    "This doesn't make much sense for tracking complex gesture trajectories; a dynamic model for a complete gesture is rarely going to be linear. We might want to be able to learn complex dynamics using a deep network, for example, and then plug them into a probabilistic filter. A Kalman filter does not support this.\n",
    "\n",
    "* all of the **uncertainty** must be normal: so we can't track multiple modes, for example, because a normal distribution has exactly one mode. \n",
    "\n",
    "Imagine an object disappearing behind an obstruction which could reappear on either side; the Kalman filter can only spread out the distribution over the whole area, with an expected location in the middle of the obstacle! We would like to instead be able to track the two possibilities here by splitting up the hypotheses. \n",
    "\n",
    "<img src=\"imgs/landscape.png\">\n",
    "*[Waddington's epigenetic landscape, illustrating a dynamic system which develops multiple modes as it evolves; a Gaussian approximation is wholly inappropriate]*\n",
    "\n",
    "Very often in HCI we encounter problems with a combination of discrete variables and continuous ones.\n",
    "This is critical in gesture recognition for example; at any point in time, our hypotheses might be split among multiple possible gestures with different spatial distributions. Being able to represent the combination of discrete + continuous states is critical. (**Kalman filter banks** are an alternative approach, which explicitly maintain the competing hypotheses as separate Kalman filters).\n",
    "\n",
    "As an aside, the **hidden Markov model**, formerly a key algorithm in speech recognition, is to discrete state tracking what the Kalman filter is to continuous state tracking. The HMM can track discrete hidden states easily (with discrete or continuous observation space), but cannot track continuous variables on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the things we need\n",
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "# add our custom scripts\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "import pfilter, gestures\n",
    "import IPython\n",
    "import matplotlib, matplotlib.colors\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(8.0, 4.0), dpi=140)\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesture recognition\n",
    "Lets now apply these ideas to a practical HCI task: recognising 2D gestures. We will try and  do the full set of gesture recognition tasks is one single, probabilistic model:\n",
    "* **spot** gestures: determine when they start and end, without any external segmentation cue like a button push.\n",
    "* **recognise** gestures: label them according to class\n",
    "* **parameterise** gestures: recover parameters like the size, speed or rotation of the gestures performed.\n",
    "\n",
    "This is a challenging task! We will assume a small set of Graffiti-like symbols as the basis for this example.\n",
    "\n",
    "We will base our algorithm directly on the one given in [A Probabilistic Framework for Matching\n",
    "Temporal Trajectories](http://www.cs.toronto.edu/~jepson/papers/BlackJepsonECCV1998.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We have some example data with a few example 2D mouse-drawn gestures. Here we are assuming just a **single** template for each gesture, for simplicity. This is a very narrow prior on the template forms. We could have formed a better prior that spans by:\n",
    "\n",
    "* averaging over multiple repetitions with some sensible combination function that aligns timing, (more robust but does not capture uncertainty) or\n",
    "* forming an approximate distribution over paths (e.g. by fitting Gaussian processes to repetitions of the templates), or\n",
    "*  just kept multiple repetitions and chosen exemplars randomly in the sampling process (easy and captures uncertainty well but inferentially inefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gestures.GestureData(\"data/gestures.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesture shapes \n",
    "We can plot the shapes of the gesture trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1120x560 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_gestures = g.n_gestures\n",
    "# plot the 2D curves\n",
    "for i in range(n_gestures):\n",
    "    plt.subplot(1, n_gestures,i+1)\n",
    "    path = g.gestures[i]    \n",
    "    plt.plot(path[:,0], -path[:,1])\n",
    "    plt.text(0,0,\"%d\"%i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeseries view\n",
    "We can also see each gesture as a trajectory of two coordinates ($x,y$ coordinates) over time. This is closer to the way in which the matching will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(n_gestures):\n",
    "    plt.subplot(n_gestures,2,i*2+1)    \n",
    "    path = g.gestures[i]    \n",
    "    plt.plot(path[:,0], '-C0')\n",
    "    plt.plot(path[:,1], '-C1')\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.subplot(n_gestures,2,i*2+2)\n",
    "    plt.plot(path[:,0], path[:,1], 'C0')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis(\"equal\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_template\n",
    "We have a simple utility function `get_template(i, t)` which returns the $x,y$ co-ordinate for gesture $i$ at sample $t$. It automatically clips $t$ from 0 to the length of the gesture (in frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_template\n",
    "for i in range(100):\n",
    "    xy = g.get_template(1, i)\n",
    "    plt.plot(xy[0], -xy[1], 'C1.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "We want to recognize 2D gestures drawn with a mouse (or finger/stylus). \n",
    "\n",
    "### We know:\n",
    "* We *observe* sequences of $x,y$ coordinates over time.\n",
    "* We have some example templates for particular shapes that we want to match (e.g. letters)\n",
    "\n",
    "### We don't know:\n",
    "* where the user will start drawing a gesture\n",
    "* how big the gesture will be    \n",
    "* how fast the user will draw the gesture (it may well be drawn at a non-constant speed)\n",
    "\n",
    "### We want to know:\n",
    "* which gesture the user is performing, if any\n",
    "* when the user has finished doing the gesture\n",
    "* the parameters of the movement, like speed of performance\n",
    "\n",
    "----- \n",
    "    \n",
    "#### Probabilistic view\n",
    "Putting this into the probabilistic framework, we want to infer a probability distribution over gesture classes and gesture completion state, given a time series of $x,y$ coordinates. The $x,y$ points form our observation vector $Y$.\n",
    "\n",
    "We assume gesture reproduction is in some way a \"noisy reproduction\" of the ideal template form, where there are various types of distortion that can be encountered. The sensing we have and the human motor system influence the production of a gesture, either communicating intentional variation (\"a rapid gesture\") or random variation (e.g. from finger tremor).\n",
    "\n",
    "#### Markov approximation\n",
    "We could look at the whole time series of $x,y$ points and try and classify that. However, there are two problems:\n",
    "* What is the \"whole\" time series -- i.e. how do we segment the gesture?\n",
    "* We would have to store the entire series and somehow match it against templates.\n",
    "\n",
    "A simple way to eliminate these problems is to rewrite the recognizer so that it depends on nothing but its immediately previous state; i.e. so that it satisfies the Markov property.\n",
    "\n",
    "To do this, we need to introduce additional variables into the state we are estimating; but with judicious choice these can be a very small number of additional variables. In particular, we can just track how far along a gesture we are (the \"phase\") and update that over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a position to write down a model for our gesture recognizer.\n",
    "\n",
    "### State\n",
    "First of all, the state we are trying to infer:\n",
    "\n",
    "<img src=\"imgs/gesture.png\">\n",
    "\n",
    "$$X = [i,s,x_c,y_c,\\theta,\\phi,\\dot{\\phi}]$$\n",
    "\n",
    "We have one of $n$ possible gestures\n",
    "* $i$ the number of the gesture\n",
    "\n",
    "Our model says a gesture will be identical to the template for that class of gesture, but might vary in:\n",
    "* $s$ overall scale, within some tolerance\n",
    "* $x_c,y_c$ center position (could be anywhere on screen)\n",
    "* $\\theta$ small changes in rotation (e.g. $<45^o$)\n",
    "\n",
    "We must take note that what we observe is a position at a **single time point** in a gesture. This means we must estimate how far through a gesture we are.\n",
    "* $\\phi$ the proportion of gesture complete, in the fraction [0,1].\n",
    "* $\\dot{\\phi}$ the rate at which the gesture is being performed (i.e. fast or slow).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "* Given a gesture $i$, we have a template $G_i(\\phi)$, which is returns an $x,y$ point for any value of $\\phi$.\n",
    "\n",
    "* We expect to observe $\\hat{{\\bf y}}=AG_i(\\phi)$, where $A$ is a transformation matrix applying the translation $x_c,y_c$, the scaling $s$ and the rotation $\\theta$.\n",
    "\n",
    "* The utility function `linear_transform()` defined below is a useful component in implementing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linear_transform(xys, angle=0.0, scale=1.0, translate=(0,0)):\n",
    "    \"\"\"Takes a an n x 2 array of point `xys` and returns the 2D points transformed by\n",
    "    rotating by `angle` (degrees)\n",
    "    scaling by `scale` (proportional 1.0=no change, 0.5=half, etc.)\n",
    "    translating by `translate` ((x,y) offset)\"\"\"\n",
    "    ca, sa = np.cos(np.radians(angle)), np.sin(np.radians(angle))\n",
    "    rot = np.array([[ca, -sa], \n",
    "                    [sa, ca]])\n",
    "    return np.dot(xys, rot)*scale + np.array(translate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo of linear transform on points distributed in a unit square\n",
    "original = np.random.uniform(0,1, size=(200,2))\n",
    "transformed = linear_transform(original, angle=45, scale=1.5, translate=(-5,2))\n",
    "plt.plot(transformed[:,0], transformed[:,1], '.')\n",
    "plt.plot(original[:,0], original[:,1], '.')\n",
    "plt.axis(\"square\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture_observation(state):\n",
    "    # given an n x d matrix of n particle samples\n",
    "    # return a n x 2 matrix of expected x,y, positions for that gesture model\n",
    "    # dummy code,which returns random results:\n",
    "  \n",
    "    transformed = [linear_transform(g.get_template(s[0], s[5]), scale=s[1], angle=0, \n",
    "                                      translate=[s[2], s[3]]) for s in state]                 \n",
    "    \n",
    "    #transformed = [linear_transform(g.get_template(s[0], s[5]), scale=1, angle=0, \n",
    "    #                                 translate=[s[2], s[3]]) for s in state]                 \n",
    "    \n",
    "    \n",
    "    return np.array(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamics\n",
    "We then specify some simple dynamics. These all allow the values to slowly change over time (i.e. some random drift), except for the phase $\\phi$ which we also expect to steadily increase at the rate $\\dot{\\phi}$.\n",
    "\n",
    "Specifically:\n",
    "* $s_{t+1} = s_{t} + \\sigma_s$ scale can drift slowly\n",
    "* $x_{t+1} = x_{t} + \\sigma_x$ position can drift slowly\n",
    "* $y_{t+1} = y_{t} + \\sigma_y$ position can drift slowly\n",
    "* $\\theta_{t+1} = \\theta_{t} + \\sigma_\\theta$ orientation can drift slowly\n",
    "* $i_{t+1}=i_{t}$  gesture class never changes\n",
    "* $\\phi_{t+1} = \\phi_{t} + \\dot{\\phi}_{t} + \\sigma_y$ progress is steady, with some drift\n",
    "* $\\dot{\\phi}_{t+1} = \\dot{\\phi}_{t} + \\sigma_y$ progress rate can drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gesture_dynamics(prev_states):\n",
    "    # take an n x d array of particle samples\n",
    "    # return an n x d array representing the next states\n",
    "    # dummy code: apply no dynamics\n",
    "    next_states = np.array(prev_states)\n",
    "    next_states[:,5] += next_states[:,6] \n",
    "\n",
    "    next_states[:,1] += np.random.normal(0,0.005,next_states[:,1].shape) # scale\n",
    "    next_states[:,2:4] += np.random.normal(0,2.0,next_states[:,2:4].shape) # pos\n",
    "    next_states[:,4] += np.random.normal(0,0.5,next_states[:,4].shape) # angle\n",
    "    next_states[:,5] += np.random.normal(0,3.0,next_states[:,5].shape)    # phi\n",
    "    next_states[:,6] += np.random.normal(0,0.2,next_states[:,6].shape)  # dphi\n",
    "    \n",
    "    return next_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Priors\n",
    "We then define our initial guesses for the state of the system, encoded as prior probability distributions.\n",
    "\n",
    "* $s_0 \\sim N(1,0.25)$, should be around original size, with some latitude\n",
    "* $x_0,y_0 \\sim U(0,\\text{max_screen_size})$, could be anywhere on screen\n",
    "* $\\theta_0 \\sim N(0,10)$, angle will be close to original, with std. dev. of ~15 degrees\n",
    "* $\\phi_0 \\sim  N(0,0.1)$, gestures will begin close to their start\n",
    "* $\\dot{\\phi}_0 \\sim  N(\\mu_{\\dot{\\phi}}, \\sigma_{\\dot{\\phi}}))$, gesture speeds will be distributed according to the observed speeds from the template\n",
    "* $i_0$ discrete $U(0,n-1)$, could be any gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture_prior(n):\n",
    "    # return an n x d matrix with columns [i, s, x_c, y_c, \\theta, \\phi, \\phi_dot] as an initial guess\n",
    "    # these should call a function draw a value from a distribution\n",
    "    # dummy code: choose a random class and set all other variables to 1.0\n",
    "    return np.stack([\n",
    "        np.random.randint(0,n_gestures,size=n), \n",
    "        np.random.normal(1.0,0.25,size=n), \n",
    "        np.random.uniform(-200,400,size=n), np.random.uniform(-200,400,size=n),\n",
    "        np.random.normal(0.0, 10.0, size=n), \n",
    "        np.random.normal(0.0, 10.0, size=n), \n",
    "        np.random.normal(1.0, 0.3, size=n)]).T\n",
    "\n",
    "# print some test samples from the prior\n",
    "print(gesture_prior(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting function\n",
    "We again use the simple heat kernel (or RBF):\n",
    "$$w_i = e^{\\left(-\\frac{(y-y^\\prime)^2}{2\\beta^2}\\right)}$$\n",
    "(the specific choice of weighting  function is rarely very important, except if there are particularly unusual states to be compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gesture_weight(hypothesized, true):\n",
    "    # take a 2D observation (x,y)\n",
    "    # and an n x 2 matrix of observation samples (returned from gesture_observation())\n",
    "    # return the weight for each, representing how similar they are\n",
    "    gesture_beta = 180.0          # the RBF width\n",
    "    \n",
    "    # RBF similarity function       \n",
    "    w = np.exp(-np.sum((hypothesized-true)**2, axis=1)/(0.5*gesture_beta**2))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gestures\n",
    "import imp\n",
    "gestures = imp.reload(gestures)\n",
    "gestures.interactive_recogniser(\n",
    "    dynamics=gesture_dynamics,\n",
    "    observation=gesture_observation,\n",
    "    prior=gesture_prior,\n",
    "    weight=gesture_weight,\n",
    "    gestures=g.gestures)\n",
    "%gui tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitfalls\n",
    "Particle filter in particular can be tricky to tune. \n",
    "\n",
    "* As the state space expands (i.e. the number of variables tracked), the number of particles requires can increase. This makes it difficult to run filters efficiently in problems that have lots of degrees of freedom.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlook\n",
    "---------------------\n",
    "### Scope and limitations\n",
    "#### Scope\n",
    "* Probabilistic filters can be applied to many problems in HCI. Typically, if a process unfolds over time and there is uncertainty, a probabilistic filter is a strong candidate for inference. \n",
    "\n",
    "* The fact that inference is performed over time is a potential advantage over \"static\" classification approaches, as feedback can be generated on the fly, instead only after completion of an action. \n",
    "\n",
    "* In the specific context of gestures, the ability to infer the start and endpoint of gestures can solve the \"segmentation problem\" or \"gesture spotting problem\" that is often awkward and leads to kludges like button presses to segment actions.\n",
    "\n",
    "* Probabilistic motion models can easily be linked to higher-order probabilistic models which infer long-term actions on the part of the user. Because everything is a probability distribution, there is a simple common basis for integrating such models. This, for example, can include language models which estimate a distribution over text that is likely to be entered given both user input and a statistical model of language.\n",
    "\n",
    "#### Limitations\n",
    "* PFs can be computationally intensive to run. \n",
    "* Curse-of-dimensionality can make the attractive simplicity of PFs work poorly in practice as the state space expands (although often better than you might expect).\n",
    "* Sometimes the inverse probability model can be hard to formulate. Conversely, it is sometimes very much easier.\n",
    "* Particle filters are simple and elegant, but inferentially weak.\n",
    "* Kalman filters are rigid and restrictive, but very inferentially efficient.\n",
    "* Hybrid approaches (Ensemble Kalman filter, Unscented Kalman Filter, hybrid particle/Kalman filters, Rao-Blackwellized filters) can trade these qualities off, but they aren't off the shelf solutions (i.e. you need an expert!).\n",
    "\n",
    "\n",
    "### Resources\n",
    "#### Basic\n",
    "* Read the [Condensation paper](http://vision.stanford.edu/teaching/cs231b_spring1415/papers/isard-blake-98.pdf).\n",
    "* Read [the Kalman filter in pictures](http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/)\n",
    "* Watch [the particle filter without equations](https://www.youtube.com/watch?v=aUkBa1zMKv4)\n",
    "\n",
    "#### Advanced\n",
    "* [A technical but succinct and clear explanation of the particle filter](http://www.cns.nyu.edu/~eorhan/notes/particle-filtering.pdf)\n",
    "* [A bibliography of particle filter papers](http://www.stats.ox.ac.uk/~doucet/smc_resources.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### Future of probabilistic filtering\n",
    "\n",
    "#### Learned models\n",
    "\n",
    "Much use of probabilistic filters has depended on strong mathematical models of the fundamental process. For example, in rocket science, sophisticated physics models were used to specify the Kalman filters used for stable control. \n",
    "\n",
    "However, it is becoming increasingly possible to **infer** these models from observations. Techniques such as deep learning (for example variational autoencoders or generative adversarial networks) make it possible to learn very sophisticated *generative models* from observations of\n",
    "data.  These models can be dropped into probabilistic filters to produce robust inferential engines for user interaction.\n",
    "\n",
    "##### Example\n",
    "As an illustrative example, we recently built a touch pose estimator to estimate the pose of a finger from a capacitive sensor array (as found on a touch screen). We trained DCNN to predict finger pose from sensor images (inverse model), a separate deconvolutional CNN to predict sensor images from finger poses (forward model) and then fused these using a particle filter.\n",
    "\n",
    "<img src=\"imgs/fwd_inv.png\">\n",
    "This combined gives substantial robustness, and we were able to introduce a simple dynamics model, which filters out completely implausible movements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
